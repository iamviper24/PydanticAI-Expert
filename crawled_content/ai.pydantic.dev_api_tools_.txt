PydanticAI
pydantic/pydantic-ai
Introduction
Installation
Getting Help
Contributing
Troubleshooting
Upgrade Guide
Documentation
Documentation
Agents
Models
Models
OpenAI
Anthropic
Gemini
Google
Bedrock
Cohere
Groq
Mistral
Dependencies
Function Tools
Common Tools
Output
Messages and chat history
Unit testing
Debugging and Monitoring
Multi-agent Applications
Graphs
Evals
Image, Audio, Video & Document Input
Thinking
Direct Model Requests
MCP
MCP
Client
Server
MCP Run Python
A2A
Command Line Interface (CLI)
Examples
Examples
Pydantic Model
Weather agent
Bank support
SQL Generation
Flight booking
RAG
Stream markdown
Stream whales
Chat App with FastAPI
Question Graph
Slack Lead Qualifier with Modal
API Reference
API Reference
pydantic_ai.agent
pydantic_ai.tools
pydantic_ai.tools
Table of contents
tools
AgentDepsT
RunContext
deps
model
usage
prompt
messages
tool_call_id
tool_name
retry
run_step
ToolParams
SystemPromptFunc
ToolFuncContext
ToolFuncPlain
ToolFuncEither
ToolPrepareFunc
ToolsPrepareFunc
DocstringFormat
Tool
__init__
function_schema
from_schema
prepare_tool_def
run
ObjectJsonSchema
ToolDefinition
name
parameters_json_schema
description
outer_typed_dict_key
strict
pydantic_ai.common_tools
pydantic_ai.output
pydantic_ai.result
pydantic_ai.messages
pydantic_ai.exceptions
pydantic_ai.settings
pydantic_ai.usage
pydantic_ai.mcp
pydantic_ai.format_as_xml
pydantic_ai.format_prompt
pydantic_ai.direct
pydantic_ai.models
pydantic_ai.models.openai
pydantic_ai.models.anthropic
pydantic_ai.models.bedrock
pydantic_ai.models.cohere
pydantic_ai.models.gemini
pydantic_ai.models.google
pydantic_ai.models.groq
pydantic_ai.models.instrumented
pydantic_ai.models.mistral
pydantic_ai.models.test
pydantic_ai.models.function
pydantic_ai.models.fallback
pydantic_ai.models.wrapper
pydantic_ai.models.mcp_sampling
pydantic_ai.profiles
pydantic_ai.providers
pydantic_graph
pydantic_graph.nodes
pydantic_graph.persistence
pydantic_graph.mermaid
pydantic_graph.exceptions
pydantic_evals.dataset
pydantic_evals.evaluators
pydantic_evals.reporting
pydantic_evals.otel
pydantic_evals.generation
fasta2a
Table of contents
tools
AgentDepsT
RunContext
deps
model
usage
prompt
messages
tool_call_id
tool_name
retry
run_step
ToolParams
SystemPromptFunc
ToolFuncContext
ToolFuncPlain
ToolFuncEither
ToolPrepareFunc
ToolsPrepareFunc
DocstringFormat
Tool
__init__
function_schema
from_schema
prepare_tool_def
run
ObjectJsonSchema
ToolDefinition
name
parameters_json_schema
description
outer_typed_dict_key
strict
pydantic_ai.tools
AgentDepsT
module-attribute
AgentDepsT
=
TypeVar
(
"AgentDepsT"
,
default
=
None
,
contravariant
=
True
)
Type variable for agent dependencies.
RunContext
dataclass
Bases:
Generic
[
AgentDepsT
]
Information about the current call.
Source code in
pydantic_ai_slim/pydantic_ai/_run_context.py
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
@dataclasses
.
dataclass
(
repr
=
False
)
class
RunContext
(
Generic
[
AgentDepsT
]):
"""Information about the current call."""
deps
:
AgentDepsT
"""Dependencies for the agent."""
model
:
Model
"""The model used in this run."""
usage
:
Usage
"""LLM usage associated with the run."""
prompt
:
str
|
Sequence
[
_messages
.
UserContent
]
|
None
"""The original user prompt passed to the run."""
messages
:
list
[
_messages
.
ModelMessage
]
=
field
(
default_factory
=
list
)
"""Messages exchanged in the conversation so far."""
tool_call_id
:
str
|
None
=
None
"""The ID of the tool call."""
tool_name
:
str
|
None
=
None
"""Name of the tool being called."""
retry
:
int
=
0
"""Number of retries so far."""
run_step
:
int
=
0
"""The current step in the run."""
def
replace_with
(
self
,
retry
:
int
|
None
=
None
,
tool_name
:
str
|
None
|
_utils
.
Unset
=
_utils
.
UNSET
,
)
->
RunContext
[
AgentDepsT
]:
# Create a new `RunContext` a new `retry` value and `tool_name`.
kwargs
=
{}
if
retry
is
not
None
:
kwargs
[
'retry'
]
=
retry
if
tool_name
is
not
_utils
.
UNSET
:
# pragma: no branch
kwargs
[
'tool_name'
]
=
tool_name
return
dataclasses
.
replace
(
self
,
**
kwargs
)
__repr__
=
_utils
.
dataclasses_no_defaults_repr
deps
instance-attribute
deps
:
AgentDepsT
Dependencies for the agent.
model
instance-attribute
model
:
Model
The model used in this run.
usage
instance-attribute
usage
:
Usage
LLM usage associated with the run.
prompt
instance-attribute
prompt
:
str
|
Sequence
[
UserContent
]
|
None
The original user prompt passed to the run.
messages
class-attribute
instance-attribute
messages
:
list
[
ModelMessage
]
=
field
(
default_factory
=
list
)
Messages exchanged in the conversation so far.
tool_call_id
class-attribute
instance-attribute
tool_call_id
:
str
|
None
=
None
The ID of the tool call.
tool_name
class-attribute
instance-attribute
tool_name
:
str
|
None
=
None
Name of the tool being called.
retry
class-attribute
instance-attribute
retry
:
int
=
0
Number of retries so far.
run_step
class-attribute
instance-attribute
run_step
:
int
=
0
The current step in the run.
ToolParams
module-attribute
ToolParams
=
ParamSpec
(
'ToolParams'
,
default
=...
)
Retrieval function param spec.
SystemPromptFunc
module-attribute
SystemPromptFunc
=
Union
[
Callable
[[
RunContext
[
AgentDepsT
]],
str
],
Callable
[[
RunContext
[
AgentDepsT
]],
Awaitable
[
str
]],
Callable
[[],
str
],
Callable
[[],
Awaitable
[
str
]],
]
A function that may or maybe not take
RunContext
as an argument, and may or may not be async.
Usage
SystemPromptFunc[AgentDepsT]
.
ToolFuncContext
module-attribute
ToolFuncContext
=
Callable
[
Concatenate
[
RunContext
[
AgentDepsT
],
ToolParams
],
Any
]
A tool function that takes
RunContext
as the first argument.
Usage
ToolContextFunc[AgentDepsT, ToolParams]
.
ToolFuncPlain
module-attribute
ToolFuncPlain
=
Callable
[
ToolParams
,
Any
]
A tool function that does not take
RunContext
as the first argument.
Usage
ToolPlainFunc[ToolParams]
.
ToolFuncEither
module-attribute
ToolFuncEither
=
Union
[
ToolFuncContext
[
AgentDepsT
,
ToolParams
],
ToolFuncPlain
[
ToolParams
],
]
Either kind of tool function.
This is just a union of
ToolFuncContext
and
ToolFuncPlain
.
Usage
ToolFuncEither[AgentDepsT, ToolParams]
.
ToolPrepareFunc
module-attribute
ToolPrepareFunc
:
TypeAlias
=
(
"Callable[[RunContext[AgentDepsT], ToolDefinition], Awaitable[ToolDefinition | None]]"
)
Definition of a function that can prepare a tool definition at call time.
See
tool docs
for more information.
Example — here
only_if_42
is valid as a
ToolPrepareFunc
:
from
typing
import
Union
from
pydantic_ai
import
RunContext
,
Tool
from
pydantic_ai.tools
import
ToolDefinition
async
def
only_if_42
(
ctx
:
RunContext
[
int
],
tool_def
:
ToolDefinition
)
->
Union
[
ToolDefinition
,
None
]:
if
ctx
.
deps
==
42
:
return
tool_def
def
hitchhiker
(
ctx
:
RunContext
[
int
],
answer
:
str
)
->
str
:
return
f
'
{
ctx
.
deps
}
{
answer
}
'
hitchhiker
=
Tool
(
hitchhiker
,
prepare
=
only_if_42
)
Usage
ToolPrepareFunc[AgentDepsT]
.
ToolsPrepareFunc
module-attribute
ToolsPrepareFunc
:
TypeAlias
=
(
"Callable[[RunContext[AgentDepsT], list[ToolDefinition]], Awaitable[list[ToolDefinition] | None]]"
)
Definition of a function that can prepare the tool definition of all tools for each step.
This is useful if you want to customize the definition of multiple tools or you want to register
a subset of tools for a given step.
Example — here
turn_on_strict_if_openai
is valid as a
ToolsPrepareFunc
:
from
dataclasses
import
replace
from
typing
import
Union
from
pydantic_ai
import
Agent
,
RunContext
from
pydantic_ai.tools
import
ToolDefinition
async
def
turn_on_strict_if_openai
(
ctx
:
RunContext
[
None
],
tool_defs
:
list
[
ToolDefinition
]
)
->
Union
[
list
[
ToolDefinition
],
None
]:
if
ctx
.
model
.
system
==
'openai'
:
return
[
replace
(
tool_def
,
strict
=
True
)
for
tool_def
in
tool_defs
]
return
tool_defs
agent
=
Agent
(
'openai:gpt-4o'
,
prepare_tools
=
turn_on_strict_if_openai
)
Usage
ToolsPrepareFunc[AgentDepsT]
.
DocstringFormat
module-attribute
DocstringFormat
=
Literal
[
"google"
,
"numpy"
,
"sphinx"
,
"auto"
]
Supported docstring formats.
'google'
—
Google-style
docstrings.
'numpy'
—
Numpy-style
docstrings.
'sphinx'
—
Sphinx-style
docstrings.
'auto'
— Automatically infer the format based on the structure of the docstring.
Tool
dataclass
Bases:
Generic
[
AgentDepsT
]
A tool function for an agent.
Source code in
pydantic_ai_slim/pydantic_ai/tools.py
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
378
379
380
381
382
383
384
385
386
387
388
389
390
391
392
393
394
395
396
397
398
399
400
401
402
403
404
405
406
407
408
409
410
411
412
413
414
415
416
417
418
419
420
421
@dataclass
(
init
=
False
)
class
Tool
(
Generic
[
AgentDepsT
]):
"""A tool function for an agent."""
function
:
ToolFuncEither
[
AgentDepsT
]
takes_ctx
:
bool
max_retries
:
int
|
None
name
:
str
description
:
str
|
None
prepare
:
ToolPrepareFunc
[
AgentDepsT
]
|
None
docstring_format
:
DocstringFormat
require_parameter_descriptions
:
bool
strict
:
bool
|
None
function_schema
:
_function_schema
.
FunctionSchema
"""
The base JSON schema for the tool's parameters.
This schema may be modified by the `prepare` function or by the Model class prior to including it in an API request.
"""
# TODO: Consider moving this current_retry state to live on something other than the tool.
#   We've worked around this for now by copying instances of the tool when creating new runs,
#   but this is a bit fragile. Moving the tool retry counts to live on the agent run state would likely clean things
#   up, though is also likely a larger effort to refactor.
current_retry
:
int
=
field
(
default
=
0
,
init
=
False
)
def
__init__
(
self
,
function
:
ToolFuncEither
[
AgentDepsT
],
*
,
takes_ctx
:
bool
|
None
=
None
,
max_retries
:
int
|
None
=
None
,
name
:
str
|
None
=
None
,
description
:
str
|
None
=
None
,
prepare
:
ToolPrepareFunc
[
AgentDepsT
]
|
None
=
None
,
docstring_format
:
DocstringFormat
=
'auto'
,
require_parameter_descriptions
:
bool
=
False
,
schema_generator
:
type
[
GenerateJsonSchema
]
=
GenerateToolJsonSchema
,
strict
:
bool
|
None
=
None
,
function_schema
:
_function_schema
.
FunctionSchema
|
None
=
None
,
):
"""Create a new tool instance.
Example usage:
```python {noqa="I001"}
from pydantic_ai import Agent, RunContext, Tool
async def my_tool(ctx: RunContext[int], x: int, y: int) -> str:
return f'{ctx.deps} {x} {y}'
agent = Agent('test', tools=[Tool(my_tool)])
```
or with a custom prepare method:
```python {noqa="I001"}
from typing import Union
from pydantic_ai import Agent, RunContext, Tool
from pydantic_ai.tools import ToolDefinition
async def my_tool(ctx: RunContext[int], x: int, y: int) -> str:
return f'{ctx.deps} {x} {y}'
async def prep_my_tool(
ctx: RunContext[int], tool_def: ToolDefinition
) -> Union[ToolDefinition, None]:
# only register the tool if `deps == 42`
if ctx.deps == 42:
return tool_def
agent = Agent('test', tools=[Tool(my_tool, prepare=prep_my_tool)])
```
Args:
function: The Python function to call as the tool.
takes_ctx: Whether the function takes a [`RunContext`][pydantic_ai.tools.RunContext] first argument,
this is inferred if unset.
max_retries: Maximum number of retries allowed for this tool, set to the agent default if `None`.
name: Name of the tool, inferred from the function if `None`.
description: Description of the tool, inferred from the function if `None`.
prepare: custom method to prepare the tool definition for each step, return `None` to omit this
tool from a given step. This is useful if you want to customise a tool at call time,
or omit it completely from a step. See [`ToolPrepareFunc`][pydantic_ai.tools.ToolPrepareFunc].
docstring_format: The format of the docstring, see [`DocstringFormat`][pydantic_ai.tools.DocstringFormat].
Defaults to `'auto'`, such that the format is inferred from the structure of the docstring.
require_parameter_descriptions: If True, raise an error if a parameter description is missing. Defaults to False.
schema_generator: The JSON schema generator class to use. Defaults to `GenerateToolJsonSchema`.
strict: Whether to enforce JSON schema compliance (only affects OpenAI).
See [`ToolDefinition`][pydantic_ai.tools.ToolDefinition] for more info.
function_schema: The function schema to use for the tool. If not provided, it will be generated.
"""
self
.
function
=
function
self
.
function_schema
=
function_schema
or
_function_schema
.
function_schema
(
function
,
schema_generator
,
takes_ctx
=
takes_ctx
,
docstring_format
=
docstring_format
,
require_parameter_descriptions
=
require_parameter_descriptions
,
)
self
.
takes_ctx
=
self
.
function_schema
.
takes_ctx
self
.
max_retries
=
max_retries
self
.
name
=
name
or
function
.
__name__
self
.
description
=
description
or
self
.
function_schema
.
description
self
.
prepare
=
prepare
self
.
docstring_format
=
docstring_format
self
.
require_parameter_descriptions
=
require_parameter_descriptions
self
.
strict
=
strict
@classmethod
def
from_schema
(
cls
,
function
:
Callable
[
...
,
Any
],
name
:
str
,
description
:
str
|
None
,
json_schema
:
JsonSchemaValue
,
)
->
Self
:
"""Creates a Pydantic tool from a function and a JSON schema.
Args:
function: The function to call.
This will be called with keywords only, and no validation of
the arguments will be performed.
name: The unique name of the tool that clearly communicates its purpose
description: Used to tell the model how/when/why to use the tool.
You can provide few-shot examples as a part of the description.
json_schema: The schema for the function arguments
Returns:
A Pydantic tool that calls the function
"""
function_schema
=
_function_schema
.
FunctionSchema
(
function
=
function
,
description
=
description
,
validator
=
SchemaValidator
(
schema
=
core_schema
.
any_schema
()),
json_schema
=
json_schema
,
takes_ctx
=
False
,
is_async
=
_utils
.
is_async_callable
(
function
),
)
return
cls
(
function
,
takes_ctx
=
False
,
name
=
name
,
description
=
description
,
function_schema
=
function_schema
,
)
async
def
prepare_tool_def
(
self
,
ctx
:
RunContext
[
AgentDepsT
])
->
ToolDefinition
|
None
:
"""Get the tool definition.
By default, this method creates a tool definition, then either returns it, or calls `self.prepare`
if it's set.
Returns:
return a `ToolDefinition` or `None` if the tools should not be registered for this run.
"""
tool_def
=
ToolDefinition
(
name
=
self
.
name
,
description
=
self
.
description
,
parameters_json_schema
=
self
.
function_schema
.
json_schema
,
strict
=
self
.
strict
,
)
if
self
.
prepare
is
not
None
:
return
await
self
.
prepare
(
ctx
,
tool_def
)
else
:
return
tool_def
async
def
run
(
self
,
message
:
_messages
.
ToolCallPart
,
run_context
:
RunContext
[
AgentDepsT
],
tracer
:
Tracer
,
include_content
:
bool
=
False
,
)
->
_messages
.
ToolReturnPart
|
_messages
.
RetryPromptPart
:
"""Run the tool function asynchronously.
This method wraps `_run` in an OpenTelemetry span.
See <https://opentelemetry.io/docs/specs/semconv/gen-ai/gen-ai-spans/#execute-tool-span>.
"""
span_attributes
=
{
'gen_ai.tool.name'
:
self
.
name
,
# NOTE: this means `gen_ai.tool.call.id` will be included even if it was generated by pydantic-ai
'gen_ai.tool.call.id'
:
message
.
tool_call_id
,
**
({
'tool_arguments'
:
message
.
args_as_json_str
()}
if
include_content
else
{}),
'logfire.msg'
:
f
'running tool:
{
self
.
name
}
'
,
# add the JSON schema so these attributes are formatted nicely in Logfire
'logfire.json_schema'
:
json
.
dumps
(
{
'type'
:
'object'
,
'properties'
:
{
**
(
{
'tool_arguments'
:
{
'type'
:
'object'
},
'tool_response'
:
{
'type'
:
'object'
},
}
if
include_content
else
{}
),
'gen_ai.tool.name'
:
{},
'gen_ai.tool.call.id'
:
{},
},
}
),
}
with
tracer
.
start_as_current_span
(
'running tool'
,
attributes
=
span_attributes
)
as
span
:
response
=
await
self
.
_run
(
message
,
run_context
)
if
include_content
and
span
.
is_recording
():
span
.
set_attribute
(
'tool_response'
,
response
.
model_response_str
()
if
isinstance
(
response
,
ToolReturnPart
)
else
response
.
model_response
(),
)
return
response
async
def
_run
(
self
,
message
:
_messages
.
ToolCallPart
,
run_context
:
RunContext
[
AgentDepsT
]
)
->
_messages
.
ToolReturnPart
|
_messages
.
RetryPromptPart
:
try
:
validator
=
self
.
function_schema
.
validator
if
isinstance
(
message
.
args
,
str
):
args_dict
=
validator
.
validate_json
(
message
.
args
or
'
{}
'
)
else
:
args_dict
=
validator
.
validate_python
(
message
.
args
or
{})
except
ValidationError
as
e
:
return
self
.
_on_error
(
e
,
message
)
ctx
=
dataclasses
.
replace
(
run_context
,
retry
=
self
.
current_retry
,
tool_name
=
message
.
tool_name
,
tool_call_id
=
message
.
tool_call_id
,
)
try
:
response_content
=
await
self
.
function_schema
.
call
(
args_dict
,
ctx
)
except
ModelRetry
as
e
:
return
self
.
_on_error
(
e
,
message
)
self
.
current_retry
=
0
return
_messages
.
ToolReturnPart
(
tool_name
=
message
.
tool_name
,
content
=
response_content
,
tool_call_id
=
message
.
tool_call_id
,
)
def
_on_error
(
self
,
exc
:
ValidationError
|
ModelRetry
,
call_message
:
_messages
.
ToolCallPart
)
->
_messages
.
RetryPromptPart
:
self
.
current_retry
+=
1
if
self
.
max_retries
is
None
or
self
.
current_retry
>
self
.
max_retries
:
raise
UnexpectedModelBehavior
(
f
'Tool exceeded max retries count of
{
self
.
max_retries
}
'
)
from
exc
else
:
if
isinstance
(
exc
,
ValidationError
):
content
=
exc
.
errors
(
include_url
=
False
,
include_context
=
False
)
else
:
content
=
exc
.
message
return
_messages
.
RetryPromptPart
(
tool_name
=
call_message
.
tool_name
,
content
=
content
,
tool_call_id
=
call_message
.
tool_call_id
,
)
__init__
__init__
(
function
:
ToolFuncEither
[
AgentDepsT
],
*
,
takes_ctx
:
bool
|
None
=
None
,
max_retries
:
int
|
None
=
None
,
name
:
str
|
None
=
None
,
description
:
str
|
None
=
None
,
prepare
:
ToolPrepareFunc
[
AgentDepsT
]
|
None
=
None
,
docstring_format
:
DocstringFormat
=
"auto"
,
require_parameter_descriptions
:
bool
=
False
,
schema_generator
:
type
[
GenerateJsonSchema
]
=
GenerateToolJsonSchema
,
strict
:
bool
|
None
=
None
,
function_schema
:
FunctionSchema
|
None
=
None
)
Create a new tool instance.
Example usage:
from
pydantic_ai
import
Agent
,
RunContext
,
Tool
async
def
my_tool
(
ctx
:
RunContext
[
int
],
x
:
int
,
y
:
int
)
->
str
:
return
f
'
{
ctx
.
deps
}
{
x
}
{
y
}
'
agent
=
Agent
(
'test'
,
tools
=
[
Tool
(
my_tool
)])
or with a custom prepare method:
from
typing
import
Union
from
pydantic_ai
import
Agent
,
RunContext
,
Tool
from
pydantic_ai.tools
import
ToolDefinition
async
def
my_tool
(
ctx
:
RunContext
[
int
],
x
:
int
,
y
:
int
)
->
str
:
return
f
'
{
ctx
.
deps
}
{
x
}
{
y
}
'
async
def
prep_my_tool
(
ctx
:
RunContext
[
int
],
tool_def
:
ToolDefinition
)
->
Union
[
ToolDefinition
,
None
]:
# only register the tool if `deps == 42`
if
ctx
.
deps
==
42
:
return
tool_def
agent
=
Agent
(
'test'
,
tools
=
[
Tool
(
my_tool
,
prepare
=
prep_my_tool
)])
Parameters:
Name
Type
Description
Default
function
ToolFuncEither
[
AgentDepsT
]
The Python function to call as the tool.
required
takes_ctx
bool
| None
Whether the function takes a
RunContext
first argument,
this is inferred if unset.
None
max_retries
int
| None
Maximum number of retries allowed for this tool, set to the agent default if
None
.
None
name
str
| None
Name of the tool, inferred from the function if
None
.
None
description
str
| None
Description of the tool, inferred from the function if
None
.
None
prepare
ToolPrepareFunc
[
AgentDepsT
] | None
custom method to prepare the tool definition for each step, return
None
to omit this
tool from a given step. This is useful if you want to customise a tool at call time,
or omit it completely from a step. See
ToolPrepareFunc
.
None
docstring_format
DocstringFormat
The format of the docstring, see
DocstringFormat
.
Defaults to
'auto'
, such that the format is inferred from the structure of the docstring.
'auto'
require_parameter_descriptions
bool
If True, raise an error if a parameter description is missing. Defaults to False.
False
schema_generator
type
[
GenerateJsonSchema
]
The JSON schema generator class to use. Defaults to
GenerateToolJsonSchema
.
GenerateToolJsonSchema
strict
bool
| None
Whether to enforce JSON schema compliance (only affects OpenAI).
See
ToolDefinition
for more info.
None
function_schema
FunctionSchema
| None
The function schema to use for the tool. If not provided, it will be generated.
None
Source code in
pydantic_ai_slim/pydantic_ai/tools.py
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
def
__init__
(
self
,
function
:
ToolFuncEither
[
AgentDepsT
],
*
,
takes_ctx
:
bool
|
None
=
None
,
max_retries
:
int
|
None
=
None
,
name
:
str
|
None
=
None
,
description
:
str
|
None
=
None
,
prepare
:
ToolPrepareFunc
[
AgentDepsT
]
|
None
=
None
,
docstring_format
:
DocstringFormat
=
'auto'
,
require_parameter_descriptions
:
bool
=
False
,
schema_generator
:
type
[
GenerateJsonSchema
]
=
GenerateToolJsonSchema
,
strict
:
bool
|
None
=
None
,
function_schema
:
_function_schema
.
FunctionSchema
|
None
=
None
,
):
"""Create a new tool instance.
Example usage:
```python {noqa="I001"}
from pydantic_ai import Agent, RunContext, Tool
async def my_tool(ctx: RunContext[int], x: int, y: int) -> str:
return f'{ctx.deps} {x} {y}'
agent = Agent('test', tools=[Tool(my_tool)])
```
or with a custom prepare method:
```python {noqa="I001"}
from typing import Union
from pydantic_ai import Agent, RunContext, Tool
from pydantic_ai.tools import ToolDefinition
async def my_tool(ctx: RunContext[int], x: int, y: int) -> str:
return f'{ctx.deps} {x} {y}'
async def prep_my_tool(
ctx: RunContext[int], tool_def: ToolDefinition
) -> Union[ToolDefinition, None]:
# only register the tool if `deps == 42`
if ctx.deps == 42:
return tool_def
agent = Agent('test', tools=[Tool(my_tool, prepare=prep_my_tool)])
```
Args:
function: The Python function to call as the tool.
takes_ctx: Whether the function takes a [`RunContext`][pydantic_ai.tools.RunContext] first argument,
this is inferred if unset.
max_retries: Maximum number of retries allowed for this tool, set to the agent default if `None`.
name: Name of the tool, inferred from the function if `None`.
description: Description of the tool, inferred from the function if `None`.
prepare: custom method to prepare the tool definition for each step, return `None` to omit this
tool from a given step. This is useful if you want to customise a tool at call time,
or omit it completely from a step. See [`ToolPrepareFunc`][pydantic_ai.tools.ToolPrepareFunc].
docstring_format: The format of the docstring, see [`DocstringFormat`][pydantic_ai.tools.DocstringFormat].
Defaults to `'auto'`, such that the format is inferred from the structure of the docstring.
require_parameter_descriptions: If True, raise an error if a parameter description is missing. Defaults to False.
schema_generator: The JSON schema generator class to use. Defaults to `GenerateToolJsonSchema`.
strict: Whether to enforce JSON schema compliance (only affects OpenAI).
See [`ToolDefinition`][pydantic_ai.tools.ToolDefinition] for more info.
function_schema: The function schema to use for the tool. If not provided, it will be generated.
"""
self
.
function
=
function
self
.
function_schema
=
function_schema
or
_function_schema
.
function_schema
(
function
,
schema_generator
,
takes_ctx
=
takes_ctx
,
docstring_format
=
docstring_format
,
require_parameter_descriptions
=
require_parameter_descriptions
,
)
self
.
takes_ctx
=
self
.
function_schema
.
takes_ctx
self
.
max_retries
=
max_retries
self
.
name
=
name
or
function
.
__name__
self
.
description
=
description
or
self
.
function_schema
.
description
self
.
prepare
=
prepare
self
.
docstring_format
=
docstring_format
self
.
require_parameter_descriptions
=
require_parameter_descriptions
self
.
strict
=
strict
function_schema
instance-attribute
function_schema
:
FunctionSchema
=
(
function_schema
or
function_schema
(
function
,
schema_generator
,
takes_ctx
=
takes_ctx
,
docstring_format
=
docstring_format
,
require_parameter_descriptions
=
require_parameter_descriptions
,
)
)
The base JSON schema for the tool's parameters.
This schema may be modified by the
prepare
function or by the Model class prior to including it in an API request.
from_schema
classmethod
from_schema
(
function
:
Callable
[
...
,
Any
],
name
:
str
,
description
:
str
|
None
,
json_schema
:
JsonSchemaValue
,
)
->
Self
Creates a Pydantic tool from a function and a JSON schema.
Parameters:
Name
Type
Description
Default
function
Callable
[...,
Any
]
The function to call.
This will be called with keywords only, and no validation of
the arguments will be performed.
required
name
str
The unique name of the tool that clearly communicates its purpose
required
description
str
| None
Used to tell the model how/when/why to use the tool.
You can provide few-shot examples as a part of the description.
required
json_schema
JsonSchemaValue
The schema for the function arguments
required
Returns:
Type
Description
Self
A Pydantic tool that calls the function
Source code in
pydantic_ai_slim/pydantic_ai/tools.py
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
@classmethod
def
from_schema
(
cls
,
function
:
Callable
[
...
,
Any
],
name
:
str
,
description
:
str
|
None
,
json_schema
:
JsonSchemaValue
,
)
->
Self
:
"""Creates a Pydantic tool from a function and a JSON schema.
Args:
function: The function to call.
This will be called with keywords only, and no validation of
the arguments will be performed.
name: The unique name of the tool that clearly communicates its purpose
description: Used to tell the model how/when/why to use the tool.
You can provide few-shot examples as a part of the description.
json_schema: The schema for the function arguments
Returns:
A Pydantic tool that calls the function
"""
function_schema
=
_function_schema
.
FunctionSchema
(
function
=
function
,
description
=
description
,
validator
=
SchemaValidator
(
schema
=
core_schema
.
any_schema
()),
json_schema
=
json_schema
,
takes_ctx
=
False
,
is_async
=
_utils
.
is_async_callable
(
function
),
)
return
cls
(
function
,
takes_ctx
=
False
,
name
=
name
,
description
=
description
,
function_schema
=
function_schema
,
)
prepare_tool_def
async
prepare_tool_def
(
ctx
:
RunContext
[
AgentDepsT
],
)
->
ToolDefinition
|
None
Get the tool definition.
By default, this method creates a tool definition, then either returns it, or calls
self.prepare
if it's set.
Returns:
Type
Description
ToolDefinition
| None
return a
ToolDefinition
or
None
if the tools should not be registered for this run.
Source code in
pydantic_ai_slim/pydantic_ai/tools.py
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
async
def
prepare_tool_def
(
self
,
ctx
:
RunContext
[
AgentDepsT
])
->
ToolDefinition
|
None
:
"""Get the tool definition.
By default, this method creates a tool definition, then either returns it, or calls `self.prepare`
if it's set.
Returns:
return a `ToolDefinition` or `None` if the tools should not be registered for this run.
"""
tool_def
=
ToolDefinition
(
name
=
self
.
name
,
description
=
self
.
description
,
parameters_json_schema
=
self
.
function_schema
.
json_schema
,
strict
=
self
.
strict
,
)
if
self
.
prepare
is
not
None
:
return
await
self
.
prepare
(
ctx
,
tool_def
)
else
:
return
tool_def
run
async
run
(
message
:
ToolCallPart
,
run_context
:
RunContext
[
AgentDepsT
],
tracer
:
Tracer
,
include_content
:
bool
=
False
,
)
->
ToolReturnPart
|
RetryPromptPart
Run the tool function asynchronously.
This method wraps
_run
in an OpenTelemetry span.
See
https://opentelemetry.io/docs/specs/semconv/gen-ai/gen-ai-spans/#execute-tool-span
.
Source code in
pydantic_ai_slim/pydantic_ai/tools.py
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
async
def
run
(
self
,
message
:
_messages
.
ToolCallPart
,
run_context
:
RunContext
[
AgentDepsT
],
tracer
:
Tracer
,
include_content
:
bool
=
False
,
)
->
_messages
.
ToolReturnPart
|
_messages
.
RetryPromptPart
:
"""Run the tool function asynchronously.
This method wraps `_run` in an OpenTelemetry span.
See <https://opentelemetry.io/docs/specs/semconv/gen-ai/gen-ai-spans/#execute-tool-span>.
"""
span_attributes
=
{
'gen_ai.tool.name'
:
self
.
name
,
# NOTE: this means `gen_ai.tool.call.id` will be included even if it was generated by pydantic-ai
'gen_ai.tool.call.id'
:
message
.
tool_call_id
,
**
({
'tool_arguments'
:
message
.
args_as_json_str
()}
if
include_content
else
{}),
'logfire.msg'
:
f
'running tool:
{
self
.
name
}
'
,
# add the JSON schema so these attributes are formatted nicely in Logfire
'logfire.json_schema'
:
json
.
dumps
(
{
'type'
:
'object'
,
'properties'
:
{
**
(
{
'tool_arguments'
:
{
'type'
:
'object'
},
'tool_response'
:
{
'type'
:
'object'
},
}
if
include_content
else
{}
),
'gen_ai.tool.name'
:
{},
'gen_ai.tool.call.id'
:
{},
},
}
),
}
with
tracer
.
start_as_current_span
(
'running tool'
,
attributes
=
span_attributes
)
as
span
:
response
=
await
self
.
_run
(
message
,
run_context
)
if
include_content
and
span
.
is_recording
():
span
.
set_attribute
(
'tool_response'
,
response
.
model_response_str
()
if
isinstance
(
response
,
ToolReturnPart
)
else
response
.
model_response
(),
)
return
response
ObjectJsonSchema
module-attribute
ObjectJsonSchema
:
TypeAlias
=
dict
[
str
,
Any
]
Type representing JSON schema of an object, e.g. where
"type": "object"
.
This type is used to define tools parameters (aka arguments) in
ToolDefinition
.
With PEP-728 this should be a TypedDict with
type: Literal['object']
, and
extra_parts=Any
ToolDefinition
dataclass
Definition of a tool passed to a model.
This is used for both function tools and output tools.
Source code in
pydantic_ai_slim/pydantic_ai/tools.py
433
434
435
436
437
438
439
440
441
442
443
444
445
446
447
448
449
450
451
452
453
454
455
456
457
458
459
460
461
462
463
464
465
466
467
@dataclass
(
repr
=
False
)
class
ToolDefinition
:
"""Definition of a tool passed to a model.
This is used for both function tools and output tools.
"""
name
:
str
"""The name of the tool."""
parameters_json_schema
:
ObjectJsonSchema
"""The JSON schema for the tool's parameters."""
description
:
str
|
None
=
None
"""The description of the tool."""
outer_typed_dict_key
:
str
|
None
=
None
"""The key in the outer [TypedDict] that wraps an output tool.
This will only be set for output tools which don't have an `object` JSON schema.
"""
strict
:
bool
|
None
=
None
"""Whether to enforce (vendor-specific) strict JSON schema validation for tool calls.
Setting this to `True` while using a supported model generally imposes some restrictions on the tool's JSON schema
in exchange for guaranteeing the API responses strictly match that schema.
When `False`, the model may be free to generate other properties or types (depending on the vendor).
When `None` (the default), the value will be inferred based on the compatibility of the parameters_json_schema.
Note: this is currently only supported by OpenAI models.
"""
__repr__
=
_utils
.
dataclasses_no_defaults_repr
name
instance-attribute
name
:
str
The name of the tool.
parameters_json_schema
instance-attribute
parameters_json_schema
:
ObjectJsonSchema
The JSON schema for the tool's parameters.
description
class-attribute
instance-attribute
description
:
str
|
None
=
None
The description of the tool.
outer_typed_dict_key
class-attribute
instance-attribute
outer_typed_dict_key
:
str
|
None
=
None
The key in the outer [TypedDict] that wraps an output tool.
This will only be set for output tools which don't have an
object
JSON schema.
strict
class-attribute
instance-attribute
strict
:
bool
|
None
=
None
Whether to enforce (vendor-specific) strict JSON schema validation for tool calls.
Setting this to
True
while using a supported model generally imposes some restrictions on the tool's JSON schema
in exchange for guaranteeing the API responses strictly match that schema.
When
False
, the model may be free to generate other properties or types (depending on the vendor).
When
None
(the default), the value will be inferred based on the compatibility of the parameters_json_schema.
Note: this is currently only supported by OpenAI models.