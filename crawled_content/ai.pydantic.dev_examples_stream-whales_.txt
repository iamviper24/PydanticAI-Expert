PydanticAI
pydantic/pydantic-ai
Introduction
Installation
Getting Help
Contributing
Troubleshooting
Upgrade Guide
Documentation
Documentation
Agents
Models
Models
OpenAI
Anthropic
Gemini
Google
Bedrock
Cohere
Groq
Mistral
Dependencies
Function Tools
Common Tools
Output
Messages and chat history
Unit testing
Debugging and Monitoring
Multi-agent Applications
Graphs
Evals
Image, Audio, Video & Document Input
Thinking
Direct Model Requests
MCP
MCP
Client
Server
MCP Run Python
A2A
Command Line Interface (CLI)
Examples
Examples
Pydantic Model
Weather agent
Bank support
SQL Generation
Flight booking
RAG
Stream markdown
Stream whales
Stream whales
Table of contents
Running the Example
Example Code
Chat App with FastAPI
Question Graph
Slack Lead Qualifier with Modal
API Reference
API Reference
pydantic_ai.agent
pydantic_ai.tools
pydantic_ai.common_tools
pydantic_ai.output
pydantic_ai.result
pydantic_ai.messages
pydantic_ai.exceptions
pydantic_ai.settings
pydantic_ai.usage
pydantic_ai.mcp
pydantic_ai.format_as_xml
pydantic_ai.format_prompt
pydantic_ai.direct
pydantic_ai.models
pydantic_ai.models.openai
pydantic_ai.models.anthropic
pydantic_ai.models.bedrock
pydantic_ai.models.cohere
pydantic_ai.models.gemini
pydantic_ai.models.google
pydantic_ai.models.groq
pydantic_ai.models.instrumented
pydantic_ai.models.mistral
pydantic_ai.models.test
pydantic_ai.models.function
pydantic_ai.models.fallback
pydantic_ai.models.wrapper
pydantic_ai.models.mcp_sampling
pydantic_ai.profiles
pydantic_ai.providers
pydantic_graph
pydantic_graph.nodes
pydantic_graph.persistence
pydantic_graph.mermaid
pydantic_graph.exceptions
pydantic_evals.dataset
pydantic_evals.evaluators
pydantic_evals.reporting
pydantic_evals.otel
pydantic_evals.generation
fasta2a
Table of contents
Running the Example
Example Code
Stream whales
Information about whales — an example of streamed structured response validation.
Demonstrates:
streaming structured output
This script streams structured responses from GPT-4 about whales, validates the data
and displays it as a dynamic table using
rich
as the data is received.
Running the Example
With
dependencies installed and environment variables set
, run:
pip
uv
python
-m
pydantic_ai_examples.stream_whales
uv
run
-m
pydantic_ai_examples.stream_whales
Should give an output like this:
Example Code
stream_whales.py
"""Information about whales — an example of streamed structured response validation.
This script streams structured responses from GPT-4 about whales, validates the data
and displays it as a dynamic table using Rich as the data is received.
Run with:
uv run -m pydantic_ai_examples.stream_whales
"""
from
typing
import
Annotated
import
logfire
from
pydantic
import
Field
from
rich.console
import
Console
from
rich.live
import
Live
from
rich.table
import
Table
from
typing_extensions
import
NotRequired
,
TypedDict
from
pydantic_ai
import
Agent
# 'if-token-present' means nothing will be sent (and the example will work) if you don't have logfire configured
logfire
.
configure
(
send_to_logfire
=
'if-token-present'
)
logfire
.
instrument_pydantic_ai
()
class
Whale
(
TypedDict
):
name
:
str
length
:
Annotated
[
float
,
Field
(
description
=
'Average length of an adult whale in meters.'
)
]
weight
:
NotRequired
[
Annotated
[
float
,
Field
(
description
=
'Average weight of an adult whale in kilograms.'
,
ge
=
50
),
]
]
ocean
:
NotRequired
[
str
]
description
:
NotRequired
[
Annotated
[
str
,
Field
(
description
=
'Short Description'
)]]
agent
=
Agent
(
'openai:gpt-4'
,
output_type
=
list
[
Whale
])
async
def
main
():
console
=
Console
()
with
Live
(
'
\n
'
*
36
,
console
=
console
)
as
live
:
console
.
print
(
'Requesting data...'
,
style
=
'cyan'
)
async
with
agent
.
run_stream
(
'Generate me details of 5 species of Whale.'
)
as
result
:
console
.
print
(
'Response:'
,
style
=
'green'
)
async
for
whales
in
result
.
stream
(
debounce_by
=
0.01
):
table
=
Table
(
title
=
'Species of Whale'
,
caption
=
'Streaming Structured responses from GPT-4'
,
width
=
120
,
)
table
.
add_column
(
'ID'
,
justify
=
'right'
)
table
.
add_column
(
'Name'
)
table
.
add_column
(
'Avg. Length (m)'
,
justify
=
'right'
)
table
.
add_column
(
'Avg. Weight (kg)'
,
justify
=
'right'
)
table
.
add_column
(
'Ocean'
)
table
.
add_column
(
'Description'
,
justify
=
'right'
)
for
wid
,
whale
in
enumerate
(
whales
,
start
=
1
):
table
.
add_row
(
str
(
wid
),
whale
[
'name'
],
f
'
{
whale
[
"length"
]
:
0.0f
}
'
,
f
'
{
w
:
0.0f
}
'
if
(
w
:=
whale
.
get
(
'weight'
))
else
'…'
,
whale
.
get
(
'ocean'
)
or
'…'
,
whale
.
get
(
'description'
)
or
'…'
,
)
live
.
update
(
table
)
if
__name__
==
'__main__'
:
import
asyncio
asyncio
.
run
(
main
())