PydanticAI
pydantic/pydantic-ai
Introduction
Installation
Getting Help
Contributing
Troubleshooting
Upgrade Guide
Documentation
Documentation
Agents
Models
Models
OpenAI
Anthropic
Gemini
Google
Bedrock
Cohere
Groq
Mistral
Dependencies
Function Tools
Common Tools
Output
Messages and chat history
Unit testing
Debugging and Monitoring
Multi-agent Applications
Graphs
Evals
Image, Audio, Video & Document Input
Thinking
Direct Model Requests
MCP
MCP
Client
Server
MCP Run Python
A2A
Command Line Interface (CLI)
Examples
Examples
Pydantic Model
Weather agent
Bank support
SQL Generation
Flight booking
RAG
Stream markdown
Stream whales
Chat App with FastAPI
Question Graph
Slack Lead Qualifier with Modal
API Reference
API Reference
pydantic_ai.agent
pydantic_ai.tools
pydantic_ai.common_tools
pydantic_ai.output
pydantic_ai.result
pydantic_ai.messages
pydantic_ai.exceptions
pydantic_ai.settings
pydantic_ai.usage
pydantic_ai.mcp
pydantic_ai.format_as_xml
pydantic_ai.format_prompt
pydantic_ai.direct
pydantic_ai.models
pydantic_ai.models.openai
pydantic_ai.models.anthropic
pydantic_ai.models.bedrock
pydantic_ai.models.cohere
pydantic_ai.models.gemini
pydantic_ai.models.google
pydantic_ai.models.groq
pydantic_ai.models.instrumented
pydantic_ai.models.mistral
pydantic_ai.models.test
pydantic_ai.models.function
pydantic_ai.models.fallback
pydantic_ai.models.wrapper
pydantic_ai.models.mcp_sampling
pydantic_ai.profiles
pydantic_ai.providers
pydantic_ai.providers
Table of contents
Provider
name
base_url
client
model_profile
google
GoogleProvider
__init__
VertexAILocation
google_vertex
GoogleVertexProvider
__init__
openai
OpenAIProvider
__init__
deepseek
DeepSeekProvider
bedrock
BedrockModelProfile
BedrockProvider
__init__
groq
GroqProvider
__init__
azure
AzureProvider
__init__
cohere
CohereProvider
__init__
MistralProvider
__init__
FireworksProvider
GrokProvider
TogetherProvider
HerokuProvider
GitHubProvider
__init__
OpenRouterProvider
pydantic_graph
pydantic_graph.nodes
pydantic_graph.persistence
pydantic_graph.mermaid
pydantic_graph.exceptions
pydantic_evals.dataset
pydantic_evals.evaluators
pydantic_evals.reporting
pydantic_evals.otel
pydantic_evals.generation
fasta2a
Table of contents
Provider
name
base_url
client
model_profile
google
GoogleProvider
__init__
VertexAILocation
google_vertex
GoogleVertexProvider
__init__
openai
OpenAIProvider
__init__
deepseek
DeepSeekProvider
bedrock
BedrockModelProfile
BedrockProvider
__init__
groq
GroqProvider
__init__
azure
AzureProvider
__init__
cohere
CohereProvider
__init__
MistralProvider
__init__
FireworksProvider
GrokProvider
TogetherProvider
HerokuProvider
GitHubProvider
__init__
OpenRouterProvider
pydantic_ai.providers
Bases:
ABC
,
Generic
[
InterfaceClient
]
Abstract class for a provider.
The provider is in charge of providing an authenticated client to the API.
Each provider only supports a specific interface. A interface can be supported by multiple providers.
For example, the OpenAIModel interface can be supported by the OpenAIProvider and the DeepSeekProvider.
Source code in
pydantic_ai_slim/pydantic_ai/providers/__init__.py
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
class
Provider
(
ABC
,
Generic
[
InterfaceClient
]):
"""Abstract class for a provider.
The provider is in charge of providing an authenticated client to the API.
Each provider only supports a specific interface. A interface can be supported by multiple providers.
For example, the OpenAIModel interface can be supported by the OpenAIProvider and the DeepSeekProvider.
"""
_client
:
InterfaceClient
@property
@abstractmethod
def
name
(
self
)
->
str
:
"""The provider name."""
raise
NotImplementedError
()
@property
@abstractmethod
def
base_url
(
self
)
->
str
:
"""The base URL for the provider API."""
raise
NotImplementedError
()
@property
@abstractmethod
def
client
(
self
)
->
InterfaceClient
:
"""The client for the provider."""
raise
NotImplementedError
()
def
model_profile
(
self
,
model_name
:
str
)
->
ModelProfile
|
None
:
"""The model profile for the named model, if available."""
return
None
# pragma: no cover
name
abstractmethod
property
name
:
str
The provider name.
base_url
abstractmethod
property
base_url
:
str
The base URL for the provider API.
client
abstractmethod
property
client
:
InterfaceClient
The client for the provider.
model_profile
model_profile
(
model_name
:
str
)
->
ModelProfile
|
None
The model profile for the named model, if available.
Source code in
pydantic_ai_slim/pydantic_ai/providers/__init__.py
46
47
48
def
model_profile
(
self
,
model_name
:
str
)
->
ModelProfile
|
None
:
"""The model profile for the named model, if available."""
return
None
# pragma: no cover
GoogleProvider
Bases:
Provider
[
Client
]
Provider for Google.
Source code in
pydantic_ai_slim/pydantic_ai/providers/google.py
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
class
GoogleProvider
(
Provider
[
genai
.
Client
]):
"""Provider for Google."""
@property
def
name
(
self
)
->
str
:
return
'google-vertex'
if
self
.
_client
.
_api_client
.
vertexai
else
'google-gla'
# type: ignore[reportPrivateUsage]
@property
def
base_url
(
self
)
->
str
:
return
str
(
self
.
_client
.
_api_client
.
_http_options
.
base_url
)
# type: ignore[reportPrivateUsage]
@property
def
client
(
self
)
->
genai
.
Client
:
return
self
.
_client
def
model_profile
(
self
,
model_name
:
str
)
->
ModelProfile
|
None
:
return
google_model_profile
(
model_name
)
@overload
def
__init__
(
self
,
*
,
api_key
:
str
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
credentials
:
Credentials
|
None
=
None
,
project
:
str
|
None
=
None
,
location
:
VertexAILocation
|
Literal
[
'global'
]
|
None
=
None
,
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
client
:
genai
.
Client
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
vertexai
:
bool
=
False
)
->
None
:
...
def
__init__
(
self
,
*
,
api_key
:
str
|
None
=
None
,
credentials
:
Credentials
|
None
=
None
,
project
:
str
|
None
=
None
,
location
:
VertexAILocation
|
Literal
[
'global'
]
|
None
=
None
,
client
:
genai
.
Client
|
None
=
None
,
vertexai
:
bool
|
None
=
None
,
)
->
None
:
"""Create a new Google provider.
Args:
api_key: The `API key <https://ai.google.dev/gemini-api/docs/api-key>`_ to
use for authentication. It can also be set via the `GOOGLE_API_KEY` environment variable.
Applies to the Gemini Developer API only.
credentials: The credentials to use for authentication when calling the Vertex AI APIs. Credentials can be
obtained from environment variables and default credentials. For more information, see Set up
Application Default Credentials. Applies to the Vertex AI API only.
project: The Google Cloud project ID to use for quota. Can be obtained from environment variables
(for example, GOOGLE_CLOUD_PROJECT). Applies to the Vertex AI API only.
location: The location to send API requests to (for example, us-central1). Can be obtained from environment variables.
Applies to the Vertex AI API only.
client: A pre-initialized client to use.
vertexai: Force the use of the Vertex AI API. If `False`, the Google Generative Language API will be used.
Defaults to `False`.
"""
if
client
is
None
:
# NOTE: We are keeping GEMINI_API_KEY for backwards compatibility.
api_key
=
api_key
or
os
.
getenv
(
'GOOGLE_API_KEY'
)
or
os
.
getenv
(
'GEMINI_API_KEY'
)
if
vertexai
is
None
:
# pragma: lax no cover
vertexai
=
bool
(
location
or
project
or
credentials
)
if
not
vertexai
:
if
api_key
is
None
:
raise
UserError
(
# pragma: no cover
'Set the `GOOGLE_API_KEY` environment variable or pass it via `GoogleProvider(api_key=...)`'
'to use the Google Generative Language API.'
)
self
.
_client
=
genai
.
Client
(
vertexai
=
vertexai
,
api_key
=
api_key
,
http_options
=
{
'headers'
:
{
'User-Agent'
:
get_user_agent
()}},
)
else
:
self
.
_client
=
genai
.
Client
(
vertexai
=
vertexai
,
project
=
project
or
os
.
environ
.
get
(
'GOOGLE_CLOUD_PROJECT'
),
# From https://github.com/pydantic/pydantic-ai/pull/2031/files#r2169682149:
# Currently `us-central1` supports the most models by far of any region including `global`, but not
# all of them. `us-central1` has all google models but is missing some Anthropic partner models,
# which use `us-east5` instead. `global` has fewer models but higher availability.
# For more details, check: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/locations#available-regions
location
=
location
or
os
.
environ
.
get
(
'GOOGLE_CLOUD_LOCATION'
)
or
'us-central1'
,
credentials
=
credentials
,
http_options
=
{
'headers'
:
{
'User-Agent'
:
get_user_agent
()}},
)
else
:
self
.
_client
=
client
# pragma: lax no cover
__init__
__init__
(
*
,
api_key
:
str
)
->
None
__init__
(
*
,
credentials
:
Credentials
|
None
=
None
,
project
:
str
|
None
=
None
,
location
:
(
VertexAILocation
|
Literal
[
"global"
]
|
None
)
=
None
)
->
None
__init__
(
*
,
client
:
Client
)
->
None
__init__
(
*
,
vertexai
:
bool
=
False
)
->
None
__init__
(
*
,
api_key
:
str
|
None
=
None
,
credentials
:
Credentials
|
None
=
None
,
project
:
str
|
None
=
None
,
location
:
(
VertexAILocation
|
Literal
[
"global"
]
|
None
)
=
None
,
client
:
Client
|
None
=
None
,
vertexai
:
bool
|
None
=
None
)
->
None
Create a new Google provider.
Parameters:
Name
Type
Description
Default
api_key
str
| None
The
API key <https://ai.google.dev/gemini-api/docs/api-key>
_ to
use for authentication. It can also be set via the
GOOGLE_API_KEY
environment variable.
Applies to the Gemini Developer API only.
None
credentials
Credentials
| None
The credentials to use for authentication when calling the Vertex AI APIs. Credentials can be
obtained from environment variables and default credentials. For more information, see Set up
Application Default Credentials. Applies to the Vertex AI API only.
None
project
str
| None
The Google Cloud project ID to use for quota. Can be obtained from environment variables
(for example, GOOGLE_CLOUD_PROJECT). Applies to the Vertex AI API only.
None
location
VertexAILocation
|
Literal
['global'] | None
The location to send API requests to (for example, us-central1). Can be obtained from environment variables.
Applies to the Vertex AI API only.
None
client
Client
| None
A pre-initialized client to use.
None
vertexai
bool
| None
Force the use of the Vertex AI API. If
False
, the Google Generative Language API will be used.
Defaults to
False
.
None
Source code in
pydantic_ai_slim/pydantic_ai/providers/google.py
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
def
__init__
(
self
,
*
,
api_key
:
str
|
None
=
None
,
credentials
:
Credentials
|
None
=
None
,
project
:
str
|
None
=
None
,
location
:
VertexAILocation
|
Literal
[
'global'
]
|
None
=
None
,
client
:
genai
.
Client
|
None
=
None
,
vertexai
:
bool
|
None
=
None
,
)
->
None
:
"""Create a new Google provider.
Args:
api_key: The `API key <https://ai.google.dev/gemini-api/docs/api-key>`_ to
use for authentication. It can also be set via the `GOOGLE_API_KEY` environment variable.
Applies to the Gemini Developer API only.
credentials: The credentials to use for authentication when calling the Vertex AI APIs. Credentials can be
obtained from environment variables and default credentials. For more information, see Set up
Application Default Credentials. Applies to the Vertex AI API only.
project: The Google Cloud project ID to use for quota. Can be obtained from environment variables
(for example, GOOGLE_CLOUD_PROJECT). Applies to the Vertex AI API only.
location: The location to send API requests to (for example, us-central1). Can be obtained from environment variables.
Applies to the Vertex AI API only.
client: A pre-initialized client to use.
vertexai: Force the use of the Vertex AI API. If `False`, the Google Generative Language API will be used.
Defaults to `False`.
"""
if
client
is
None
:
# NOTE: We are keeping GEMINI_API_KEY for backwards compatibility.
api_key
=
api_key
or
os
.
getenv
(
'GOOGLE_API_KEY'
)
or
os
.
getenv
(
'GEMINI_API_KEY'
)
if
vertexai
is
None
:
# pragma: lax no cover
vertexai
=
bool
(
location
or
project
or
credentials
)
if
not
vertexai
:
if
api_key
is
None
:
raise
UserError
(
# pragma: no cover
'Set the `GOOGLE_API_KEY` environment variable or pass it via `GoogleProvider(api_key=...)`'
'to use the Google Generative Language API.'
)
self
.
_client
=
genai
.
Client
(
vertexai
=
vertexai
,
api_key
=
api_key
,
http_options
=
{
'headers'
:
{
'User-Agent'
:
get_user_agent
()}},
)
else
:
self
.
_client
=
genai
.
Client
(
vertexai
=
vertexai
,
project
=
project
or
os
.
environ
.
get
(
'GOOGLE_CLOUD_PROJECT'
),
# From https://github.com/pydantic/pydantic-ai/pull/2031/files#r2169682149:
# Currently `us-central1` supports the most models by far of any region including `global`, but not
# all of them. `us-central1` has all google models but is missing some Anthropic partner models,
# which use `us-east5` instead. `global` has fewer models but higher availability.
# For more details, check: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/locations#available-regions
location
=
location
or
os
.
environ
.
get
(
'GOOGLE_CLOUD_LOCATION'
)
or
'us-central1'
,
credentials
=
credentials
,
http_options
=
{
'headers'
:
{
'User-Agent'
:
get_user_agent
()}},
)
else
:
self
.
_client
=
client
# pragma: lax no cover
VertexAILocation
module-attribute
VertexAILocation
=
Literal
[
"asia-east1"
,
"asia-east2"
,
"asia-northeast1"
,
"asia-northeast3"
,
"asia-south1"
,
"asia-southeast1"
,
"australia-southeast1"
,
"europe-central2"
,
"europe-north1"
,
"europe-southwest1"
,
"europe-west1"
,
"europe-west2"
,
"europe-west3"
,
"europe-west4"
,
"europe-west6"
,
"europe-west8"
,
"europe-west9"
,
"me-central1"
,
"me-central2"
,
"me-west1"
,
"northamerica-northeast1"
,
"southamerica-east1"
,
"us-central1"
,
"us-east1"
,
"us-east4"
,
"us-east5"
,
"us-south1"
,
"us-west1"
,
"us-west4"
,
]
Regions available for Vertex AI.
More details
here
.
GoogleVertexProvider
Bases:
Provider
[
AsyncClient
]
Provider for Vertex AI API.
Source code in
pydantic_ai_slim/pydantic_ai/providers/google_vertex.py
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
class
GoogleVertexProvider
(
Provider
[
httpx
.
AsyncClient
]):
"""Provider for Vertex AI API."""
@property
def
name
(
self
)
->
str
:
return
'google-vertex'
@property
def
base_url
(
self
)
->
str
:
return
(
f
'https://
{
self
.
region
}
-aiplatform.googleapis.com/v1'
f
'/projects/
{
self
.
project_id
}
'
f
'/locations/
{
self
.
region
}
'
f
'/publishers/
{
self
.
model_publisher
}
/models/'
)
@property
def
client
(
self
)
->
httpx
.
AsyncClient
:
return
self
.
_client
def
model_profile
(
self
,
model_name
:
str
)
->
ModelProfile
|
None
:
return
google_model_profile
(
model_name
)
# pragma: lax no cover
@overload
def
__init__
(
self
,
*
,
service_account_file
:
Path
|
str
|
None
=
None
,
project_id
:
str
|
None
=
None
,
region
:
VertexAiRegion
=
'us-central1'
,
model_publisher
:
str
=
'google'
,
http_client
:
httpx
.
AsyncClient
|
None
=
None
,
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
service_account_info
:
Mapping
[
str
,
str
]
|
None
=
None
,
project_id
:
str
|
None
=
None
,
region
:
VertexAiRegion
=
'us-central1'
,
model_publisher
:
str
=
'google'
,
http_client
:
httpx
.
AsyncClient
|
None
=
None
,
)
->
None
:
...
def
__init__
(
self
,
*
,
service_account_file
:
Path
|
str
|
None
=
None
,
service_account_info
:
Mapping
[
str
,
str
]
|
None
=
None
,
project_id
:
str
|
None
=
None
,
region
:
VertexAiRegion
=
'us-central1'
,
model_publisher
:
str
=
'google'
,
http_client
:
httpx
.
AsyncClient
|
None
=
None
,
)
->
None
:
"""Create a new Vertex AI provider.
Args:
service_account_file: Path to a service account file.
If not provided, the service_account_info or default environment credentials will be used.
service_account_info: The loaded service_account_file contents.
If not provided, the service_account_file or default environment credentials will be used.
project_id: The project ID to use, if not provided it will be taken from the credentials.
region: The region to make requests to.
model_publisher: The model publisher to use, I couldn't find a good list of available publishers,
and from trial and error it seems non-google models don't work with the `generateContent` and
`streamGenerateContent` functions, hence only `google` is currently supported.
Please create an issue or PR if you know how to use other publishers.
http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.
"""
if
service_account_file
and
service_account_info
:
raise
ValueError
(
'Only one of `service_account_file` or `service_account_info` can be provided.'
)
self
.
_client
=
http_client
or
cached_async_http_client
(
provider
=
'google-vertex'
)
self
.
service_account_file
=
service_account_file
self
.
service_account_info
=
service_account_info
self
.
project_id
=
project_id
self
.
region
=
region
self
.
model_publisher
=
model_publisher
self
.
_client
.
auth
=
_VertexAIAuth
(
service_account_file
,
service_account_info
,
project_id
,
region
)
self
.
_client
.
base_url
=
self
.
base_url
__init__
__init__
(
*
,
service_account_file
:
Path
|
str
|
None
=
None
,
project_id
:
str
|
None
=
None
,
region
:
VertexAiRegion
=
"us-central1"
,
model_publisher
:
str
=
"google"
,
http_client
:
AsyncClient
|
None
=
None
)
->
None
__init__
(
*
,
service_account_info
:
Mapping
[
str
,
str
]
|
None
=
None
,
project_id
:
str
|
None
=
None
,
region
:
VertexAiRegion
=
"us-central1"
,
model_publisher
:
str
=
"google"
,
http_client
:
AsyncClient
|
None
=
None
)
->
None
__init__
(
*
,
service_account_file
:
Path
|
str
|
None
=
None
,
service_account_info
:
Mapping
[
str
,
str
]
|
None
=
None
,
project_id
:
str
|
None
=
None
,
region
:
VertexAiRegion
=
"us-central1"
,
model_publisher
:
str
=
"google"
,
http_client
:
AsyncClient
|
None
=
None
)
->
None
Create a new Vertex AI provider.
Parameters:
Name
Type
Description
Default
service_account_file
Path
|
str
| None
Path to a service account file.
If not provided, the service_account_info or default environment credentials will be used.
None
service_account_info
Mapping
[
str
,
str
] | None
The loaded service_account_file contents.
If not provided, the service_account_file or default environment credentials will be used.
None
project_id
str
| None
The project ID to use, if not provided it will be taken from the credentials.
None
region
VertexAiRegion
The region to make requests to.
'us-central1'
model_publisher
str
The model publisher to use, I couldn't find a good list of available publishers,
and from trial and error it seems non-google models don't work with the
generateContent
and
streamGenerateContent
functions, hence only
google
is currently supported.
Please create an issue or PR if you know how to use other publishers.
'google'
http_client
AsyncClient
| None
An existing
httpx.AsyncClient
to use for making HTTP requests.
None
Source code in
pydantic_ai_slim/pydantic_ai/providers/google_vertex.py
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
def
__init__
(
self
,
*
,
service_account_file
:
Path
|
str
|
None
=
None
,
service_account_info
:
Mapping
[
str
,
str
]
|
None
=
None
,
project_id
:
str
|
None
=
None
,
region
:
VertexAiRegion
=
'us-central1'
,
model_publisher
:
str
=
'google'
,
http_client
:
httpx
.
AsyncClient
|
None
=
None
,
)
->
None
:
"""Create a new Vertex AI provider.
Args:
service_account_file: Path to a service account file.
If not provided, the service_account_info or default environment credentials will be used.
service_account_info: The loaded service_account_file contents.
If not provided, the service_account_file or default environment credentials will be used.
project_id: The project ID to use, if not provided it will be taken from the credentials.
region: The region to make requests to.
model_publisher: The model publisher to use, I couldn't find a good list of available publishers,
and from trial and error it seems non-google models don't work with the `generateContent` and
`streamGenerateContent` functions, hence only `google` is currently supported.
Please create an issue or PR if you know how to use other publishers.
http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.
"""
if
service_account_file
and
service_account_info
:
raise
ValueError
(
'Only one of `service_account_file` or `service_account_info` can be provided.'
)
self
.
_client
=
http_client
or
cached_async_http_client
(
provider
=
'google-vertex'
)
self
.
service_account_file
=
service_account_file
self
.
service_account_info
=
service_account_info
self
.
project_id
=
project_id
self
.
region
=
region
self
.
model_publisher
=
model_publisher
self
.
_client
.
auth
=
_VertexAIAuth
(
service_account_file
,
service_account_info
,
project_id
,
region
)
self
.
_client
.
base_url
=
self
.
base_url
OpenAIProvider
Bases:
Provider
[
AsyncOpenAI
]
Provider for OpenAI API.
Source code in
pydantic_ai_slim/pydantic_ai/providers/openai.py
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
class
OpenAIProvider
(
Provider
[
AsyncOpenAI
]):
"""Provider for OpenAI API."""
@property
def
name
(
self
)
->
str
:
return
'openai'
# pragma: no cover
@property
def
base_url
(
self
)
->
str
:
return
str
(
self
.
client
.
base_url
)
@property
def
client
(
self
)
->
AsyncOpenAI
:
return
self
.
_client
def
model_profile
(
self
,
model_name
:
str
)
->
ModelProfile
|
None
:
return
openai_model_profile
(
model_name
)
def
__init__
(
self
,
base_url
:
str
|
None
=
None
,
api_key
:
str
|
None
=
None
,
openai_client
:
AsyncOpenAI
|
None
=
None
,
http_client
:
httpx
.
AsyncClient
|
None
=
None
,
)
->
None
:
"""Create a new OpenAI provider.
Args:
base_url: The base url for the OpenAI requests. If not provided, the `OPENAI_BASE_URL` environment variable
will be used if available. Otherwise, defaults to OpenAI's base url.
api_key: The API key to use for authentication, if not provided, the `OPENAI_API_KEY` environment variable
will be used if available.
openai_client: An existing
[`AsyncOpenAI`](https://github.com/openai/openai-python?tab=readme-ov-file#async-usage)
client to use. If provided, `base_url`, `api_key`, and `http_client` must be `None`.
http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.
"""
# This is a workaround for the OpenAI client requiring an API key, whilst locally served,
# openai compatible models do not always need an API key, but a placeholder (non-empty) key is required.
if
api_key
is
None
and
'OPENAI_API_KEY'
not
in
os
.
environ
and
base_url
is
not
None
and
openai_client
is
None
:
api_key
=
'api-key-not-set'
if
openai_client
is
not
None
:
assert
base_url
is
None
,
'Cannot provide both `openai_client` and `base_url`'
assert
http_client
is
None
,
'Cannot provide both `openai_client` and `http_client`'
assert
api_key
is
None
,
'Cannot provide both `openai_client` and `api_key`'
self
.
_client
=
openai_client
elif
http_client
is
not
None
:
self
.
_client
=
AsyncOpenAI
(
base_url
=
base_url
,
api_key
=
api_key
,
http_client
=
http_client
)
else
:
http_client
=
cached_async_http_client
(
provider
=
'openai'
)
self
.
_client
=
AsyncOpenAI
(
base_url
=
base_url
,
api_key
=
api_key
,
http_client
=
http_client
)
__init__
__init__
(
base_url
:
str
|
None
=
None
,
api_key
:
str
|
None
=
None
,
openai_client
:
AsyncOpenAI
|
None
=
None
,
http_client
:
AsyncClient
|
None
=
None
,
)
->
None
Create a new OpenAI provider.
Parameters:
Name
Type
Description
Default
base_url
str
| None
The base url for the OpenAI requests. If not provided, the
OPENAI_BASE_URL
environment variable
will be used if available. Otherwise, defaults to OpenAI's base url.
None
api_key
str
| None
The API key to use for authentication, if not provided, the
OPENAI_API_KEY
environment variable
will be used if available.
None
openai_client
AsyncOpenAI
| None
An existing
AsyncOpenAI
client to use. If provided,
base_url
,
api_key
, and
http_client
must be
None
.
None
http_client
AsyncClient
| None
An existing
httpx.AsyncClient
to use for making HTTP requests.
None
Source code in
pydantic_ai_slim/pydantic_ai/providers/openai.py
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
def
__init__
(
self
,
base_url
:
str
|
None
=
None
,
api_key
:
str
|
None
=
None
,
openai_client
:
AsyncOpenAI
|
None
=
None
,
http_client
:
httpx
.
AsyncClient
|
None
=
None
,
)
->
None
:
"""Create a new OpenAI provider.
Args:
base_url: The base url for the OpenAI requests. If not provided, the `OPENAI_BASE_URL` environment variable
will be used if available. Otherwise, defaults to OpenAI's base url.
api_key: The API key to use for authentication, if not provided, the `OPENAI_API_KEY` environment variable
will be used if available.
openai_client: An existing
[`AsyncOpenAI`](https://github.com/openai/openai-python?tab=readme-ov-file#async-usage)
client to use. If provided, `base_url`, `api_key`, and `http_client` must be `None`.
http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.
"""
# This is a workaround for the OpenAI client requiring an API key, whilst locally served,
# openai compatible models do not always need an API key, but a placeholder (non-empty) key is required.
if
api_key
is
None
and
'OPENAI_API_KEY'
not
in
os
.
environ
and
base_url
is
not
None
and
openai_client
is
None
:
api_key
=
'api-key-not-set'
if
openai_client
is
not
None
:
assert
base_url
is
None
,
'Cannot provide both `openai_client` and `base_url`'
assert
http_client
is
None
,
'Cannot provide both `openai_client` and `http_client`'
assert
api_key
is
None
,
'Cannot provide both `openai_client` and `api_key`'
self
.
_client
=
openai_client
elif
http_client
is
not
None
:
self
.
_client
=
AsyncOpenAI
(
base_url
=
base_url
,
api_key
=
api_key
,
http_client
=
http_client
)
else
:
http_client
=
cached_async_http_client
(
provider
=
'openai'
)
self
.
_client
=
AsyncOpenAI
(
base_url
=
base_url
,
api_key
=
api_key
,
http_client
=
http_client
)
DeepSeekProvider
Bases:
Provider
[
AsyncOpenAI
]
Provider for DeepSeek API.
Source code in
pydantic_ai_slim/pydantic_ai/providers/deepseek.py
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
class
DeepSeekProvider
(
Provider
[
AsyncOpenAI
]):
"""Provider for DeepSeek API."""
@property
def
name
(
self
)
->
str
:
return
'deepseek'
@property
def
base_url
(
self
)
->
str
:
return
'https://api.deepseek.com'
@property
def
client
(
self
)
->
AsyncOpenAI
:
return
self
.
_client
def
model_profile
(
self
,
model_name
:
str
)
->
ModelProfile
|
None
:
profile
=
deepseek_model_profile
(
model_name
)
# As DeepSeekProvider is always used with OpenAIModel, which used to unconditionally use OpenAIJsonSchemaTransformer,
# we need to maintain that behavior unless json_schema_transformer is set explicitly.
# This was not the case when using a DeepSeek model with another model class (e.g. BedrockConverseModel or GroqModel),
# so we won't do this in `deepseek_model_profile` unless we learn it's always needed.
return
OpenAIModelProfile
(
json_schema_transformer
=
OpenAIJsonSchemaTransformer
)
.
update
(
profile
)
@overload
def
__init__
(
self
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
api_key
:
str
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
api_key
:
str
,
http_client
:
AsyncHTTPClient
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
openai_client
:
AsyncOpenAI
|
None
=
None
)
->
None
:
...
def
__init__
(
self
,
*
,
api_key
:
str
|
None
=
None
,
openai_client
:
AsyncOpenAI
|
None
=
None
,
http_client
:
AsyncHTTPClient
|
None
=
None
,
)
->
None
:
api_key
=
api_key
or
os
.
getenv
(
'DEEPSEEK_API_KEY'
)
if
not
api_key
and
openai_client
is
None
:
raise
UserError
(
'Set the `DEEPSEEK_API_KEY` environment variable or pass it via `DeepSeekProvider(api_key=...)`'
'to use the DeepSeek provider.'
)
if
openai_client
is
not
None
:
self
.
_client
=
openai_client
elif
http_client
is
not
None
:
self
.
_client
=
AsyncOpenAI
(
base_url
=
self
.
base_url
,
api_key
=
api_key
,
http_client
=
http_client
)
else
:
http_client
=
cached_async_http_client
(
provider
=
'deepseek'
)
self
.
_client
=
AsyncOpenAI
(
base_url
=
self
.
base_url
,
api_key
=
api_key
,
http_client
=
http_client
)
BedrockModelProfile
dataclass
Bases:
ModelProfile
Profile for models used with BedrockModel.
ALL FIELDS MUST BE
bedrock_
PREFIXED SO YOU CAN MERGE THEM WITH OTHER MODELS.
Source code in
pydantic_ai_slim/pydantic_ai/providers/bedrock.py
30
31
32
33
34
35
36
37
38
@dataclass
class
BedrockModelProfile
(
ModelProfile
):
"""Profile for models used with BedrockModel.
ALL FIELDS MUST BE `bedrock_` PREFIXED SO YOU CAN MERGE THEM WITH OTHER MODELS.
"""
bedrock_supports_tool_choice
:
bool
=
True
bedrock_tool_result_format
:
Literal
[
'text'
,
'json'
]
=
'text'
BedrockProvider
Bases:
Provider
[
BaseClient
]
Provider for AWS Bedrock.
Source code in
pydantic_ai_slim/pydantic_ai/providers/bedrock.py
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
class
BedrockProvider
(
Provider
[
BaseClient
]):
"""Provider for AWS Bedrock."""
@property
def
name
(
self
)
->
str
:
return
'bedrock'
@property
def
base_url
(
self
)
->
str
:
return
self
.
_client
.
meta
.
endpoint_url
@property
def
client
(
self
)
->
BaseClient
:
return
self
.
_client
def
model_profile
(
self
,
model_name
:
str
)
->
ModelProfile
|
None
:
provider_to_profile
:
dict
[
str
,
Callable
[[
str
],
ModelProfile
|
None
]]
=
{
'anthropic'
:
lambda
model_name
:
BedrockModelProfile
(
bedrock_supports_tool_choice
=
False
)
.
update
(
anthropic_model_profile
(
model_name
)
),
'mistral'
:
lambda
model_name
:
BedrockModelProfile
(
bedrock_tool_result_format
=
'json'
)
.
update
(
mistral_model_profile
(
model_name
)
),
'cohere'
:
cohere_model_profile
,
'amazon'
:
amazon_model_profile
,
'meta'
:
meta_model_profile
,
'deepseek'
:
deepseek_model_profile
,
}
# Split the model name into parts
parts
=
model_name
.
split
(
'.'
,
2
)
# Handle regional prefixes (e.g. "us.")
if
len
(
parts
)
>
2
and
len
(
parts
[
0
])
==
2
:
parts
=
parts
[
1
:]
if
len
(
parts
)
<
2
:
return
None
provider
=
parts
[
0
]
model_name_with_version
=
parts
[
1
]
# Remove version suffix if it matches the format (e.g. "-v1:0" or "-v14")
version_match
=
re
.
match
(
r
'(.+)-v\d+(?::\d+)?$'
,
model_name_with_version
)
if
version_match
:
model_name
=
version_match
.
group
(
1
)
else
:
model_name
=
model_name_with_version
if
provider
in
provider_to_profile
:
return
provider_to_profile
[
provider
](
model_name
)
return
None
@overload
def
__init__
(
self
,
*
,
bedrock_client
:
BaseClient
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
region_name
:
str
|
None
=
None
,
aws_access_key_id
:
str
|
None
=
None
,
aws_secret_access_key
:
str
|
None
=
None
,
aws_session_token
:
str
|
None
=
None
,
profile_name
:
str
|
None
=
None
,
aws_read_timeout
:
float
|
None
=
None
,
aws_connect_timeout
:
float
|
None
=
None
,
)
->
None
:
...
def
__init__
(
self
,
*
,
bedrock_client
:
BaseClient
|
None
=
None
,
region_name
:
str
|
None
=
None
,
aws_access_key_id
:
str
|
None
=
None
,
aws_secret_access_key
:
str
|
None
=
None
,
aws_session_token
:
str
|
None
=
None
,
profile_name
:
str
|
None
=
None
,
aws_read_timeout
:
float
|
None
=
None
,
aws_connect_timeout
:
float
|
None
=
None
,
)
->
None
:
"""Initialize the Bedrock provider.
Args:
bedrock_client: A boto3 client for Bedrock Runtime. If provided, other arguments are ignored.
region_name: The AWS region name.
aws_access_key_id: The AWS access key ID.
aws_secret_access_key: The AWS secret access key.
aws_session_token: The AWS session token.
profile_name: The AWS profile name.
aws_read_timeout: The read timeout for Bedrock client.
aws_connect_timeout: The connect timeout for Bedrock client.
"""
if
bedrock_client
is
not
None
:
self
.
_client
=
bedrock_client
else
:
try
:
read_timeout
=
aws_read_timeout
or
float
(
os
.
getenv
(
'AWS_READ_TIMEOUT'
,
300
))
connect_timeout
=
aws_connect_timeout
or
float
(
os
.
getenv
(
'AWS_CONNECT_TIMEOUT'
,
60
))
session
=
boto3
.
Session
(
aws_access_key_id
=
aws_access_key_id
,
aws_secret_access_key
=
aws_secret_access_key
,
aws_session_token
=
aws_session_token
,
region_name
=
region_name
,
profile_name
=
profile_name
,
)
self
.
_client
=
session
.
client
(
# type: ignore[reportUnknownMemberType]
'bedrock-runtime'
,
config
=
Config
(
read_timeout
=
read_timeout
,
connect_timeout
=
connect_timeout
),
)
except
NoRegionError
as
exc
:
# pragma: no cover
raise
UserError
(
'You must provide a `region_name` or a boto3 client for Bedrock Runtime.'
)
from
exc
__init__
__init__
(
*
,
bedrock_client
:
BaseClient
)
->
None
__init__
(
*
,
region_name
:
str
|
None
=
None
,
aws_access_key_id
:
str
|
None
=
None
,
aws_secret_access_key
:
str
|
None
=
None
,
aws_session_token
:
str
|
None
=
None
,
profile_name
:
str
|
None
=
None
,
aws_read_timeout
:
float
|
None
=
None
,
aws_connect_timeout
:
float
|
None
=
None
)
->
None
__init__
(
*
,
bedrock_client
:
BaseClient
|
None
=
None
,
region_name
:
str
|
None
=
None
,
aws_access_key_id
:
str
|
None
=
None
,
aws_secret_access_key
:
str
|
None
=
None
,
aws_session_token
:
str
|
None
=
None
,
profile_name
:
str
|
None
=
None
,
aws_read_timeout
:
float
|
None
=
None
,
aws_connect_timeout
:
float
|
None
=
None
)
->
None
Initialize the Bedrock provider.
Parameters:
Name
Type
Description
Default
bedrock_client
BaseClient
| None
A boto3 client for Bedrock Runtime. If provided, other arguments are ignored.
None
region_name
str
| None
The AWS region name.
None
aws_access_key_id
str
| None
The AWS access key ID.
None
aws_secret_access_key
str
| None
The AWS secret access key.
None
aws_session_token
str
| None
The AWS session token.
None
profile_name
str
| None
The AWS profile name.
None
aws_read_timeout
float
| None
The read timeout for Bedrock client.
None
aws_connect_timeout
float
| None
The connect timeout for Bedrock client.
None
Source code in
pydantic_ai_slim/pydantic_ai/providers/bedrock.py
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
def
__init__
(
self
,
*
,
bedrock_client
:
BaseClient
|
None
=
None
,
region_name
:
str
|
None
=
None
,
aws_access_key_id
:
str
|
None
=
None
,
aws_secret_access_key
:
str
|
None
=
None
,
aws_session_token
:
str
|
None
=
None
,
profile_name
:
str
|
None
=
None
,
aws_read_timeout
:
float
|
None
=
None
,
aws_connect_timeout
:
float
|
None
=
None
,
)
->
None
:
"""Initialize the Bedrock provider.
Args:
bedrock_client: A boto3 client for Bedrock Runtime. If provided, other arguments are ignored.
region_name: The AWS region name.
aws_access_key_id: The AWS access key ID.
aws_secret_access_key: The AWS secret access key.
aws_session_token: The AWS session token.
profile_name: The AWS profile name.
aws_read_timeout: The read timeout for Bedrock client.
aws_connect_timeout: The connect timeout for Bedrock client.
"""
if
bedrock_client
is
not
None
:
self
.
_client
=
bedrock_client
else
:
try
:
read_timeout
=
aws_read_timeout
or
float
(
os
.
getenv
(
'AWS_READ_TIMEOUT'
,
300
))
connect_timeout
=
aws_connect_timeout
or
float
(
os
.
getenv
(
'AWS_CONNECT_TIMEOUT'
,
60
))
session
=
boto3
.
Session
(
aws_access_key_id
=
aws_access_key_id
,
aws_secret_access_key
=
aws_secret_access_key
,
aws_session_token
=
aws_session_token
,
region_name
=
region_name
,
profile_name
=
profile_name
,
)
self
.
_client
=
session
.
client
(
# type: ignore[reportUnknownMemberType]
'bedrock-runtime'
,
config
=
Config
(
read_timeout
=
read_timeout
,
connect_timeout
=
connect_timeout
),
)
except
NoRegionError
as
exc
:
# pragma: no cover
raise
UserError
(
'You must provide a `region_name` or a boto3 client for Bedrock Runtime.'
)
from
exc
GroqProvider
Bases:
Provider
[
AsyncGroq
]
Provider for Groq API.
Source code in
pydantic_ai_slim/pydantic_ai/providers/groq.py
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
class
GroqProvider
(
Provider
[
AsyncGroq
]):
"""Provider for Groq API."""
@property
def
name
(
self
)
->
str
:
return
'groq'
@property
def
base_url
(
self
)
->
str
:
return
os
.
environ
.
get
(
'GROQ_BASE_URL'
,
'https://api.groq.com'
)
@property
def
client
(
self
)
->
AsyncGroq
:
return
self
.
_client
def
model_profile
(
self
,
model_name
:
str
)
->
ModelProfile
|
None
:
prefix_to_profile
=
{
'llama'
:
meta_model_profile
,
'meta-llama/'
:
meta_model_profile
,
'gemma'
:
google_model_profile
,
'qwen'
:
qwen_model_profile
,
'deepseek'
:
deepseek_model_profile
,
'mistral'
:
mistral_model_profile
,
}
for
prefix
,
profile_func
in
prefix_to_profile
.
items
():
model_name
=
model_name
.
lower
()
if
model_name
.
startswith
(
prefix
):
if
prefix
.
endswith
(
'/'
):
model_name
=
model_name
[
len
(
prefix
)
:]
return
profile_func
(
model_name
)
return
None
@overload
def
__init__
(
self
,
*
,
groq_client
:
AsyncGroq
|
None
=
None
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
api_key
:
str
|
None
=
None
,
http_client
:
AsyncHTTPClient
|
None
=
None
)
->
None
:
...
def
__init__
(
self
,
*
,
api_key
:
str
|
None
=
None
,
groq_client
:
AsyncGroq
|
None
=
None
,
http_client
:
AsyncHTTPClient
|
None
=
None
,
)
->
None
:
"""Create a new Groq provider.
Args:
api_key: The API key to use for authentication, if not provided, the `GROQ_API_KEY` environment variable
will be used if available.
groq_client: An existing
[`AsyncGroq`](https://github.com/groq/groq-python?tab=readme-ov-file#async-usage)
client to use. If provided, `api_key` and `http_client` must be `None`.
http_client: An existing `AsyncHTTPClient` to use for making HTTP requests.
"""
if
groq_client
is
not
None
:
assert
http_client
is
None
,
'Cannot provide both `groq_client` and `http_client`'
assert
api_key
is
None
,
'Cannot provide both `groq_client` and `api_key`'
self
.
_client
=
groq_client
else
:
api_key
=
api_key
or
os
.
environ
.
get
(
'GROQ_API_KEY'
)
if
not
api_key
:
raise
UserError
(
'Set the `GROQ_API_KEY` environment variable or pass it via `GroqProvider(api_key=...)`'
'to use the Groq provider.'
)
elif
http_client
is
not
None
:
self
.
_client
=
AsyncGroq
(
base_url
=
self
.
base_url
,
api_key
=
api_key
,
http_client
=
http_client
)
else
:
http_client
=
cached_async_http_client
(
provider
=
'groq'
)
self
.
_client
=
AsyncGroq
(
base_url
=
self
.
base_url
,
api_key
=
api_key
,
http_client
=
http_client
)
__init__
__init__
(
*
,
groq_client
:
AsyncGroq
|
None
=
None
)
->
None
__init__
(
*
,
api_key
:
str
|
None
=
None
,
http_client
:
AsyncClient
|
None
=
None
)
->
None
__init__
(
*
,
api_key
:
str
|
None
=
None
,
groq_client
:
AsyncGroq
|
None
=
None
,
http_client
:
AsyncClient
|
None
=
None
)
->
None
Create a new Groq provider.
Parameters:
Name
Type
Description
Default
api_key
str
| None
The API key to use for authentication, if not provided, the
GROQ_API_KEY
environment variable
will be used if available.
None
groq_client
AsyncGroq
| None
An existing
AsyncGroq
client to use. If provided,
api_key
and
http_client
must be
None
.
None
http_client
AsyncClient
| None
An existing
AsyncHTTPClient
to use for making HTTP requests.
None
Source code in
pydantic_ai_slim/pydantic_ai/providers/groq.py
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
def
__init__
(
self
,
*
,
api_key
:
str
|
None
=
None
,
groq_client
:
AsyncGroq
|
None
=
None
,
http_client
:
AsyncHTTPClient
|
None
=
None
,
)
->
None
:
"""Create a new Groq provider.
Args:
api_key: The API key to use for authentication, if not provided, the `GROQ_API_KEY` environment variable
will be used if available.
groq_client: An existing
[`AsyncGroq`](https://github.com/groq/groq-python?tab=readme-ov-file#async-usage)
client to use. If provided, `api_key` and `http_client` must be `None`.
http_client: An existing `AsyncHTTPClient` to use for making HTTP requests.
"""
if
groq_client
is
not
None
:
assert
http_client
is
None
,
'Cannot provide both `groq_client` and `http_client`'
assert
api_key
is
None
,
'Cannot provide both `groq_client` and `api_key`'
self
.
_client
=
groq_client
else
:
api_key
=
api_key
or
os
.
environ
.
get
(
'GROQ_API_KEY'
)
if
not
api_key
:
raise
UserError
(
'Set the `GROQ_API_KEY` environment variable or pass it via `GroqProvider(api_key=...)`'
'to use the Groq provider.'
)
elif
http_client
is
not
None
:
self
.
_client
=
AsyncGroq
(
base_url
=
self
.
base_url
,
api_key
=
api_key
,
http_client
=
http_client
)
else
:
http_client
=
cached_async_http_client
(
provider
=
'groq'
)
self
.
_client
=
AsyncGroq
(
base_url
=
self
.
base_url
,
api_key
=
api_key
,
http_client
=
http_client
)
AzureProvider
Bases:
Provider
[
AsyncOpenAI
]
Provider for Azure OpenAI API.
See
https://azure.microsoft.com/en-us/products/ai-foundry
for more information.
Source code in
pydantic_ai_slim/pydantic_ai/providers/azure.py
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
class
AzureProvider
(
Provider
[
AsyncOpenAI
]):
"""Provider for Azure OpenAI API.
See <https://azure.microsoft.com/en-us/products/ai-foundry> for more information.
"""
@property
def
name
(
self
)
->
str
:
return
'azure'
@property
def
base_url
(
self
)
->
str
:
assert
self
.
_base_url
is
not
None
return
self
.
_base_url
@property
def
client
(
self
)
->
AsyncOpenAI
:
return
self
.
_client
def
model_profile
(
self
,
model_name
:
str
)
->
ModelProfile
|
None
:
model_name
=
model_name
.
lower
()
prefix_to_profile
=
{
'llama'
:
meta_model_profile
,
'meta-'
:
meta_model_profile
,
'deepseek'
:
deepseek_model_profile
,
'mistralai-'
:
mistral_model_profile
,
'mistral'
:
mistral_model_profile
,
'cohere-'
:
cohere_model_profile
,
'grok'
:
grok_model_profile
,
}
for
prefix
,
profile_func
in
prefix_to_profile
.
items
():
if
model_name
.
startswith
(
prefix
):
if
prefix
.
endswith
(
'-'
):
model_name
=
model_name
[
len
(
prefix
)
:]
profile
=
profile_func
(
model_name
)
# As AzureProvider is always used with OpenAIModel, which used to unconditionally use OpenAIJsonSchemaTransformer,
# we need to maintain that behavior unless json_schema_transformer is set explicitly
return
OpenAIModelProfile
(
json_schema_transformer
=
OpenAIJsonSchemaTransformer
)
.
update
(
profile
)
# OpenAI models are unprefixed
return
openai_model_profile
(
model_name
)
@overload
def
__init__
(
self
,
*
,
openai_client
:
AsyncAzureOpenAI
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
azure_endpoint
:
str
|
None
=
None
,
api_version
:
str
|
None
=
None
,
api_key
:
str
|
None
=
None
,
http_client
:
httpx
.
AsyncClient
|
None
=
None
,
)
->
None
:
...
def
__init__
(
self
,
*
,
azure_endpoint
:
str
|
None
=
None
,
api_version
:
str
|
None
=
None
,
api_key
:
str
|
None
=
None
,
openai_client
:
AsyncAzureOpenAI
|
None
=
None
,
http_client
:
httpx
.
AsyncClient
|
None
=
None
,
)
->
None
:
"""Create a new Azure provider.
Args:
azure_endpoint: The Azure endpoint to use for authentication, if not provided, the `AZURE_OPENAI_ENDPOINT`
environment variable will be used if available.
api_version: The API version to use for authentication, if not provided, the `OPENAI_API_VERSION`
environment variable will be used if available.
api_key: The API key to use for authentication, if not provided, the `AZURE_OPENAI_API_KEY` environment variable
will be used if available.
openai_client: An existing
[`AsyncAzureOpenAI`](https://github.com/openai/openai-python#microsoft-azure-openai)
client to use. If provided, `base_url`, `api_key`, and `http_client` must be `None`.
http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.
"""
if
openai_client
is
not
None
:
assert
azure_endpoint
is
None
,
'Cannot provide both `openai_client` and `azure_endpoint`'
assert
http_client
is
None
,
'Cannot provide both `openai_client` and `http_client`'
assert
api_key
is
None
,
'Cannot provide both `openai_client` and `api_key`'
self
.
_base_url
=
str
(
openai_client
.
base_url
)
self
.
_client
=
openai_client
else
:
azure_endpoint
=
azure_endpoint
or
os
.
getenv
(
'AZURE_OPENAI_ENDPOINT'
)
if
not
azure_endpoint
:
raise
UserError
(
'Must provide one of the `azure_endpoint` argument or the `AZURE_OPENAI_ENDPOINT` environment variable'
)
if
not
api_key
and
'AZURE_OPENAI_API_KEY'
not
in
os
.
environ
:
# pragma: no cover
raise
UserError
(
'Must provide one of the `api_key` argument or the `AZURE_OPENAI_API_KEY` environment variable'
)
if
not
api_version
and
'OPENAI_API_VERSION'
not
in
os
.
environ
:
# pragma: no cover
raise
UserError
(
'Must provide one of the `api_version` argument or the `OPENAI_API_VERSION` environment variable'
)
http_client
=
http_client
or
cached_async_http_client
(
provider
=
'azure'
)
self
.
_client
=
AsyncAzureOpenAI
(
azure_endpoint
=
azure_endpoint
,
api_key
=
api_key
,
api_version
=
api_version
,
http_client
=
http_client
,
)
self
.
_base_url
=
str
(
self
.
_client
.
base_url
)
__init__
__init__
(
*
,
openai_client
:
AsyncAzureOpenAI
)
->
None
__init__
(
*
,
azure_endpoint
:
str
|
None
=
None
,
api_version
:
str
|
None
=
None
,
api_key
:
str
|
None
=
None
,
http_client
:
AsyncClient
|
None
=
None
)
->
None
__init__
(
*
,
azure_endpoint
:
str
|
None
=
None
,
api_version
:
str
|
None
=
None
,
api_key
:
str
|
None
=
None
,
openai_client
:
AsyncAzureOpenAI
|
None
=
None
,
http_client
:
AsyncClient
|
None
=
None
)
->
None
Create a new Azure provider.
Parameters:
Name
Type
Description
Default
azure_endpoint
str
| None
The Azure endpoint to use for authentication, if not provided, the
AZURE_OPENAI_ENDPOINT
environment variable will be used if available.
None
api_version
str
| None
The API version to use for authentication, if not provided, the
OPENAI_API_VERSION
environment variable will be used if available.
None
api_key
str
| None
The API key to use for authentication, if not provided, the
AZURE_OPENAI_API_KEY
environment variable
will be used if available.
None
openai_client
AsyncAzureOpenAI
| None
An existing
AsyncAzureOpenAI
client to use. If provided,
base_url
,
api_key
, and
http_client
must be
None
.
None
http_client
AsyncClient
| None
An existing
httpx.AsyncClient
to use for making HTTP requests.
None
Source code in
pydantic_ai_slim/pydantic_ai/providers/azure.py
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
def
__init__
(
self
,
*
,
azure_endpoint
:
str
|
None
=
None
,
api_version
:
str
|
None
=
None
,
api_key
:
str
|
None
=
None
,
openai_client
:
AsyncAzureOpenAI
|
None
=
None
,
http_client
:
httpx
.
AsyncClient
|
None
=
None
,
)
->
None
:
"""Create a new Azure provider.
Args:
azure_endpoint: The Azure endpoint to use for authentication, if not provided, the `AZURE_OPENAI_ENDPOINT`
environment variable will be used if available.
api_version: The API version to use for authentication, if not provided, the `OPENAI_API_VERSION`
environment variable will be used if available.
api_key: The API key to use for authentication, if not provided, the `AZURE_OPENAI_API_KEY` environment variable
will be used if available.
openai_client: An existing
[`AsyncAzureOpenAI`](https://github.com/openai/openai-python#microsoft-azure-openai)
client to use. If provided, `base_url`, `api_key`, and `http_client` must be `None`.
http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.
"""
if
openai_client
is
not
None
:
assert
azure_endpoint
is
None
,
'Cannot provide both `openai_client` and `azure_endpoint`'
assert
http_client
is
None
,
'Cannot provide both `openai_client` and `http_client`'
assert
api_key
is
None
,
'Cannot provide both `openai_client` and `api_key`'
self
.
_base_url
=
str
(
openai_client
.
base_url
)
self
.
_client
=
openai_client
else
:
azure_endpoint
=
azure_endpoint
or
os
.
getenv
(
'AZURE_OPENAI_ENDPOINT'
)
if
not
azure_endpoint
:
raise
UserError
(
'Must provide one of the `azure_endpoint` argument or the `AZURE_OPENAI_ENDPOINT` environment variable'
)
if
not
api_key
and
'AZURE_OPENAI_API_KEY'
not
in
os
.
environ
:
# pragma: no cover
raise
UserError
(
'Must provide one of the `api_key` argument or the `AZURE_OPENAI_API_KEY` environment variable'
)
if
not
api_version
and
'OPENAI_API_VERSION'
not
in
os
.
environ
:
# pragma: no cover
raise
UserError
(
'Must provide one of the `api_version` argument or the `OPENAI_API_VERSION` environment variable'
)
http_client
=
http_client
or
cached_async_http_client
(
provider
=
'azure'
)
self
.
_client
=
AsyncAzureOpenAI
(
azure_endpoint
=
azure_endpoint
,
api_key
=
api_key
,
api_version
=
api_version
,
http_client
=
http_client
,
)
self
.
_base_url
=
str
(
self
.
_client
.
base_url
)
CohereProvider
Bases:
Provider
[
AsyncClientV2
]
Provider for Cohere API.
Source code in
pydantic_ai_slim/pydantic_ai/providers/cohere.py
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
class
CohereProvider
(
Provider
[
AsyncClientV2
]):
"""Provider for Cohere API."""
@property
def
name
(
self
)
->
str
:
return
'cohere'
@property
def
base_url
(
self
)
->
str
:
client_wrapper
=
self
.
client
.
_client_wrapper
# type: ignore
return
str
(
client_wrapper
.
get_base_url
())
@property
def
client
(
self
)
->
AsyncClientV2
:
return
self
.
_client
def
model_profile
(
self
,
model_name
:
str
)
->
ModelProfile
|
None
:
return
cohere_model_profile
(
model_name
)
def
__init__
(
self
,
*
,
api_key
:
str
|
None
=
None
,
cohere_client
:
AsyncClientV2
|
None
=
None
,
http_client
:
AsyncHTTPClient
|
None
=
None
,
)
->
None
:
"""Create a new Cohere provider.
Args:
api_key: The API key to use for authentication, if not provided, the `CO_API_KEY` environment variable
will be used if available.
cohere_client: An existing
[AsyncClientV2](https://github.com/cohere-ai/cohere-python)
client to use. If provided, `api_key` and `http_client` must be `None`.
http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.
"""
if
cohere_client
is
not
None
:
assert
http_client
is
None
,
'Cannot provide both `cohere_client` and `http_client`'
assert
api_key
is
None
,
'Cannot provide both `cohere_client` and `api_key`'
self
.
_client
=
cohere_client
else
:
api_key
=
api_key
or
os
.
environ
.
get
(
'CO_API_KEY'
)
if
not
api_key
:
raise
UserError
(
'Set the `CO_API_KEY` environment variable or pass it via `CohereProvider(api_key=...)`'
'to use the Cohere provider.'
)
base_url
=
os
.
environ
.
get
(
'CO_BASE_URL'
)
if
http_client
is
not
None
:
self
.
_client
=
AsyncClientV2
(
api_key
=
api_key
,
httpx_client
=
http_client
,
base_url
=
base_url
)
else
:
http_client
=
cached_async_http_client
(
provider
=
'cohere'
)
self
.
_client
=
AsyncClientV2
(
api_key
=
api_key
,
httpx_client
=
http_client
,
base_url
=
base_url
)
__init__
__init__
(
*
,
api_key
:
str
|
None
=
None
,
cohere_client
:
AsyncClientV2
|
None
=
None
,
http_client
:
AsyncClient
|
None
=
None
)
->
None
Create a new Cohere provider.
Parameters:
Name
Type
Description
Default
api_key
str
| None
The API key to use for authentication, if not provided, the
CO_API_KEY
environment variable
will be used if available.
None
cohere_client
AsyncClientV2
| None
An existing
AsyncClientV2
client to use. If provided,
api_key
and
http_client
must be
None
.
None
http_client
AsyncClient
| None
An existing
httpx.AsyncClient
to use for making HTTP requests.
None
Source code in
pydantic_ai_slim/pydantic_ai/providers/cohere.py
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
def
__init__
(
self
,
*
,
api_key
:
str
|
None
=
None
,
cohere_client
:
AsyncClientV2
|
None
=
None
,
http_client
:
AsyncHTTPClient
|
None
=
None
,
)
->
None
:
"""Create a new Cohere provider.
Args:
api_key: The API key to use for authentication, if not provided, the `CO_API_KEY` environment variable
will be used if available.
cohere_client: An existing
[AsyncClientV2](https://github.com/cohere-ai/cohere-python)
client to use. If provided, `api_key` and `http_client` must be `None`.
http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.
"""
if
cohere_client
is
not
None
:
assert
http_client
is
None
,
'Cannot provide both `cohere_client` and `http_client`'
assert
api_key
is
None
,
'Cannot provide both `cohere_client` and `api_key`'
self
.
_client
=
cohere_client
else
:
api_key
=
api_key
or
os
.
environ
.
get
(
'CO_API_KEY'
)
if
not
api_key
:
raise
UserError
(
'Set the `CO_API_KEY` environment variable or pass it via `CohereProvider(api_key=...)`'
'to use the Cohere provider.'
)
base_url
=
os
.
environ
.
get
(
'CO_BASE_URL'
)
if
http_client
is
not
None
:
self
.
_client
=
AsyncClientV2
(
api_key
=
api_key
,
httpx_client
=
http_client
,
base_url
=
base_url
)
else
:
http_client
=
cached_async_http_client
(
provider
=
'cohere'
)
self
.
_client
=
AsyncClientV2
(
api_key
=
api_key
,
httpx_client
=
http_client
,
base_url
=
base_url
)
Bases:
Provider
[
Mistral
]
Provider for Mistral API.
Source code in
pydantic_ai_slim/pydantic_ai/providers/mistral.py
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
class
MistralProvider
(
Provider
[
Mistral
]):
"""Provider for Mistral API."""
@property
def
name
(
self
)
->
str
:
return
'mistral'
@property
def
base_url
(
self
)
->
str
:
return
self
.
client
.
sdk_configuration
.
get_server_details
()[
0
]
@property
def
client
(
self
)
->
Mistral
:
return
self
.
_client
def
model_profile
(
self
,
model_name
:
str
)
->
ModelProfile
|
None
:
return
mistral_model_profile
(
model_name
)
@overload
def
__init__
(
self
,
*
,
mistral_client
:
Mistral
|
None
=
None
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
api_key
:
str
|
None
=
None
,
http_client
:
AsyncHTTPClient
|
None
=
None
)
->
None
:
...
def
__init__
(
self
,
*
,
api_key
:
str
|
None
=
None
,
mistral_client
:
Mistral
|
None
=
None
,
base_url
:
str
|
None
=
None
,
http_client
:
AsyncHTTPClient
|
None
=
None
,
)
->
None
:
"""Create a new Mistral provider.
Args:
api_key: The API key to use for authentication, if not provided, the `MISTRAL_API_KEY` environment variable
will be used if available.
mistral_client: An existing `Mistral` client to use, if provided, `api_key` and `http_client` must be `None`.
base_url: The base url for the Mistral requests.
http_client: An existing async client to use for making HTTP requests.
"""
if
mistral_client
is
not
None
:
assert
http_client
is
None
,
'Cannot provide both `mistral_client` and `http_client`'
assert
api_key
is
None
,
'Cannot provide both `mistral_client` and `api_key`'
assert
base_url
is
None
,
'Cannot provide both `mistral_client` and `base_url`'
self
.
_client
=
mistral_client
else
:
api_key
=
api_key
or
os
.
environ
.
get
(
'MISTRAL_API_KEY'
)
if
not
api_key
:
raise
UserError
(
'Set the `MISTRAL_API_KEY` environment variable or pass it via `MistralProvider(api_key=...)`'
'to use the Mistral provider.'
)
elif
http_client
is
not
None
:
self
.
_client
=
Mistral
(
api_key
=
api_key
,
async_client
=
http_client
,
server_url
=
base_url
)
else
:
http_client
=
cached_async_http_client
(
provider
=
'mistral'
)
self
.
_client
=
Mistral
(
api_key
=
api_key
,
async_client
=
http_client
,
server_url
=
base_url
)
__init__
__init__
(
*
,
mistral_client
:
Mistral
|
None
=
None
)
->
None
__init__
(
*
,
api_key
:
str
|
None
=
None
,
http_client
:
AsyncClient
|
None
=
None
)
->
None
__init__
(
*
,
api_key
:
str
|
None
=
None
,
mistral_client
:
Mistral
|
None
=
None
,
base_url
:
str
|
None
=
None
,
http_client
:
AsyncClient
|
None
=
None
)
->
None
Create a new Mistral provider.
Parameters:
Name
Type
Description
Default
api_key
str
| None
The API key to use for authentication, if not provided, the
MISTRAL_API_KEY
environment variable
will be used if available.
None
mistral_client
Mistral
| None
An existing
Mistral
client to use, if provided,
api_key
and
http_client
must be
None
.
None
base_url
str
| None
The base url for the Mistral requests.
None
http_client
AsyncClient
| None
An existing async client to use for making HTTP requests.
None
Source code in
pydantic_ai_slim/pydantic_ai/providers/mistral.py
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
def
__init__
(
self
,
*
,
api_key
:
str
|
None
=
None
,
mistral_client
:
Mistral
|
None
=
None
,
base_url
:
str
|
None
=
None
,
http_client
:
AsyncHTTPClient
|
None
=
None
,
)
->
None
:
"""Create a new Mistral provider.
Args:
api_key: The API key to use for authentication, if not provided, the `MISTRAL_API_KEY` environment variable
will be used if available.
mistral_client: An existing `Mistral` client to use, if provided, `api_key` and `http_client` must be `None`.
base_url: The base url for the Mistral requests.
http_client: An existing async client to use for making HTTP requests.
"""
if
mistral_client
is
not
None
:
assert
http_client
is
None
,
'Cannot provide both `mistral_client` and `http_client`'
assert
api_key
is
None
,
'Cannot provide both `mistral_client` and `api_key`'
assert
base_url
is
None
,
'Cannot provide both `mistral_client` and `base_url`'
self
.
_client
=
mistral_client
else
:
api_key
=
api_key
or
os
.
environ
.
get
(
'MISTRAL_API_KEY'
)
if
not
api_key
:
raise
UserError
(
'Set the `MISTRAL_API_KEY` environment variable or pass it via `MistralProvider(api_key=...)`'
'to use the Mistral provider.'
)
elif
http_client
is
not
None
:
self
.
_client
=
Mistral
(
api_key
=
api_key
,
async_client
=
http_client
,
server_url
=
base_url
)
else
:
http_client
=
cached_async_http_client
(
provider
=
'mistral'
)
self
.
_client
=
Mistral
(
api_key
=
api_key
,
async_client
=
http_client
,
server_url
=
base_url
)
Bases:
Provider
[
AsyncOpenAI
]
Provider for Fireworks AI API.
Source code in
pydantic_ai_slim/pydantic_ai/providers/fireworks.py
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
class
FireworksProvider
(
Provider
[
AsyncOpenAI
]):
"""Provider for Fireworks AI API."""
@property
def
name
(
self
)
->
str
:
return
'fireworks'
@property
def
base_url
(
self
)
->
str
:
return
'https://api.fireworks.ai/inference/v1'
@property
def
client
(
self
)
->
AsyncOpenAI
:
return
self
.
_client
def
model_profile
(
self
,
model_name
:
str
)
->
ModelProfile
|
None
:
prefix_to_profile
=
{
'llama'
:
meta_model_profile
,
'qwen'
:
qwen_model_profile
,
'deepseek'
:
deepseek_model_profile
,
'mistral'
:
mistral_model_profile
,
'gemma'
:
google_model_profile
,
}
prefix
=
'accounts/fireworks/models/'
profile
=
None
if
model_name
.
startswith
(
prefix
):
model_name
=
model_name
[
len
(
prefix
)
:]
for
provider
,
profile_func
in
prefix_to_profile
.
items
():
if
model_name
.
startswith
(
provider
):
profile
=
profile_func
(
model_name
)
break
# As the Fireworks API is OpenAI-compatible, let's assume we also need OpenAIJsonSchemaTransformer,
# unless json_schema_transformer is set explicitly
return
OpenAIModelProfile
(
json_schema_transformer
=
OpenAIJsonSchemaTransformer
)
.
update
(
profile
)
@overload
def
__init__
(
self
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
api_key
:
str
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
api_key
:
str
,
http_client
:
AsyncHTTPClient
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
openai_client
:
AsyncOpenAI
|
None
=
None
)
->
None
:
...
def
__init__
(
self
,
*
,
api_key
:
str
|
None
=
None
,
openai_client
:
AsyncOpenAI
|
None
=
None
,
http_client
:
AsyncHTTPClient
|
None
=
None
,
)
->
None
:
api_key
=
api_key
or
os
.
getenv
(
'FIREWORKS_API_KEY'
)
if
not
api_key
and
openai_client
is
None
:
raise
UserError
(
'Set the `FIREWORKS_API_KEY` environment variable or pass it via `FireworksProvider(api_key=...)`'
'to use the Fireworks AI provider.'
)
if
openai_client
is
not
None
:
self
.
_client
=
openai_client
elif
http_client
is
not
None
:
self
.
_client
=
AsyncOpenAI
(
base_url
=
self
.
base_url
,
api_key
=
api_key
,
http_client
=
http_client
)
else
:
http_client
=
cached_async_http_client
(
provider
=
'fireworks'
)
self
.
_client
=
AsyncOpenAI
(
base_url
=
self
.
base_url
,
api_key
=
api_key
,
http_client
=
http_client
)
Bases:
Provider
[
AsyncOpenAI
]
Provider for Grok API.
Source code in
pydantic_ai_slim/pydantic_ai/providers/grok.py
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
class
GrokProvider
(
Provider
[
AsyncOpenAI
]):
"""Provider for Grok API."""
@property
def
name
(
self
)
->
str
:
return
'grok'
@property
def
base_url
(
self
)
->
str
:
return
'https://api.x.ai/v1'
@property
def
client
(
self
)
->
AsyncOpenAI
:
return
self
.
_client
def
model_profile
(
self
,
model_name
:
str
)
->
ModelProfile
|
None
:
profile
=
grok_model_profile
(
model_name
)
# As the Grok API is OpenAI-compatible, let's assume we also need OpenAIJsonSchemaTransformer,
# unless json_schema_transformer is set explicitly.
# Also, Grok does not support strict tool definitions: https://github.com/pydantic/pydantic-ai/issues/1846
return
OpenAIModelProfile
(
json_schema_transformer
=
OpenAIJsonSchemaTransformer
,
openai_supports_strict_tool_definition
=
False
)
.
update
(
profile
)
@overload
def
__init__
(
self
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
api_key
:
str
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
api_key
:
str
,
http_client
:
AsyncHTTPClient
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
openai_client
:
AsyncOpenAI
|
None
=
None
)
->
None
:
...
def
__init__
(
self
,
*
,
api_key
:
str
|
None
=
None
,
openai_client
:
AsyncOpenAI
|
None
=
None
,
http_client
:
AsyncHTTPClient
|
None
=
None
,
)
->
None
:
api_key
=
api_key
or
os
.
getenv
(
'GROK_API_KEY'
)
if
not
api_key
and
openai_client
is
None
:
raise
UserError
(
'Set the `GROK_API_KEY` environment variable or pass it via `GrokProvider(api_key=...)`'
'to use the Grok provider.'
)
if
openai_client
is
not
None
:
self
.
_client
=
openai_client
elif
http_client
is
not
None
:
self
.
_client
=
AsyncOpenAI
(
base_url
=
self
.
base_url
,
api_key
=
api_key
,
http_client
=
http_client
)
else
:
http_client
=
cached_async_http_client
(
provider
=
'grok'
)
self
.
_client
=
AsyncOpenAI
(
base_url
=
self
.
base_url
,
api_key
=
api_key
,
http_client
=
http_client
)
Bases:
Provider
[
AsyncOpenAI
]
Provider for Together AI API.
Source code in
pydantic_ai_slim/pydantic_ai/providers/together.py
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
class
TogetherProvider
(
Provider
[
AsyncOpenAI
]):
"""Provider for Together AI API."""
@property
def
name
(
self
)
->
str
:
return
'together'
@property
def
base_url
(
self
)
->
str
:
return
'https://api.together.xyz/v1'
@property
def
client
(
self
)
->
AsyncOpenAI
:
return
self
.
_client
def
model_profile
(
self
,
model_name
:
str
)
->
ModelProfile
|
None
:
provider_to_profile
=
{
'deepseek-ai'
:
deepseek_model_profile
,
'google'
:
google_model_profile
,
'qwen'
:
qwen_model_profile
,
'meta-llama'
:
meta_model_profile
,
'mistralai'
:
mistral_model_profile
,
}
profile
=
None
model_name
=
model_name
.
lower
()
provider
,
model_name
=
model_name
.
split
(
'/'
,
1
)
if
provider
in
provider_to_profile
:
profile
=
provider_to_profile
[
provider
](
model_name
)
# As the Together API is OpenAI-compatible, let's assume we also need OpenAIJsonSchemaTransformer,
# unless json_schema_transformer is set explicitly
return
OpenAIModelProfile
(
json_schema_transformer
=
OpenAIJsonSchemaTransformer
)
.
update
(
profile
)
@overload
def
__init__
(
self
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
api_key
:
str
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
api_key
:
str
,
http_client
:
AsyncHTTPClient
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
openai_client
:
AsyncOpenAI
|
None
=
None
)
->
None
:
...
def
__init__
(
self
,
*
,
api_key
:
str
|
None
=
None
,
openai_client
:
AsyncOpenAI
|
None
=
None
,
http_client
:
AsyncHTTPClient
|
None
=
None
,
)
->
None
:
api_key
=
api_key
or
os
.
getenv
(
'TOGETHER_API_KEY'
)
if
not
api_key
and
openai_client
is
None
:
raise
UserError
(
'Set the `TOGETHER_API_KEY` environment variable or pass it via `TogetherProvider(api_key=...)`'
'to use the Together AI provider.'
)
if
openai_client
is
not
None
:
self
.
_client
=
openai_client
elif
http_client
is
not
None
:
self
.
_client
=
AsyncOpenAI
(
base_url
=
self
.
base_url
,
api_key
=
api_key
,
http_client
=
http_client
)
else
:
http_client
=
cached_async_http_client
(
provider
=
'together'
)
self
.
_client
=
AsyncOpenAI
(
base_url
=
self
.
base_url
,
api_key
=
api_key
,
http_client
=
http_client
)
Bases:
Provider
[
AsyncOpenAI
]
Provider for Heroku API.
Source code in
pydantic_ai_slim/pydantic_ai/providers/heroku.py
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
class
HerokuProvider
(
Provider
[
AsyncOpenAI
]):
"""Provider for Heroku API."""
@property
def
name
(
self
)
->
str
:
return
'heroku'
@property
def
base_url
(
self
)
->
str
:
return
str
(
self
.
client
.
base_url
)
@property
def
client
(
self
)
->
AsyncOpenAI
:
return
self
.
_client
def
model_profile
(
self
,
model_name
:
str
)
->
ModelProfile
|
None
:
# As the Heroku API is OpenAI-compatible, let's assume we also need OpenAIJsonSchemaTransformer.
return
OpenAIModelProfile
(
json_schema_transformer
=
OpenAIJsonSchemaTransformer
)
@overload
def
__init__
(
self
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
api_key
:
str
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
api_key
:
str
,
http_client
:
AsyncHTTPClient
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
openai_client
:
AsyncOpenAI
|
None
=
None
)
->
None
:
...
def
__init__
(
self
,
*
,
base_url
:
str
|
None
=
None
,
api_key
:
str
|
None
=
None
,
openai_client
:
AsyncOpenAI
|
None
=
None
,
http_client
:
AsyncHTTPClient
|
None
=
None
,
)
->
None
:
if
openai_client
is
not
None
:
assert
http_client
is
None
,
'Cannot provide both `openai_client` and `http_client`'
assert
api_key
is
None
,
'Cannot provide both `openai_client` and `api_key`'
self
.
_client
=
openai_client
else
:
api_key
=
api_key
or
os
.
environ
.
get
(
'HEROKU_INFERENCE_KEY'
)
if
not
api_key
:
raise
UserError
(
'Set the `HEROKU_INFERENCE_KEY` environment variable or pass it via `HerokuProvider(api_key=...)`'
'to use the Heroku provider.'
)
base_url
=
base_url
or
os
.
environ
.
get
(
'HEROKU_INFERENCE_URL'
,
'https://us.inference.heroku.com'
)
base_url
=
base_url
.
rstrip
(
'/'
)
+
'/v1'
if
http_client
is
not
None
:
self
.
_client
=
AsyncOpenAI
(
api_key
=
api_key
,
http_client
=
http_client
,
base_url
=
base_url
)
else
:
http_client
=
cached_async_http_client
(
provider
=
'heroku'
)
self
.
_client
=
AsyncOpenAI
(
api_key
=
api_key
,
http_client
=
http_client
,
base_url
=
base_url
)
Bases:
Provider
[
AsyncOpenAI
]
Provider for GitHub Models API.
GitHub Models provides access to various AI models through an OpenAI-compatible API.
See
https://docs.github.com/en/github-models
for more information.
Source code in
pydantic_ai_slim/pydantic_ai/providers/github.py
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
class
GitHubProvider
(
Provider
[
AsyncOpenAI
]):
"""Provider for GitHub Models API.
GitHub Models provides access to various AI models through an OpenAI-compatible API.
See <https://docs.github.com/en/github-models> for more information.
"""
@property
def
name
(
self
)
->
str
:
return
'github'
@property
def
base_url
(
self
)
->
str
:
return
'https://models.github.ai/inference'
@property
def
client
(
self
)
->
AsyncOpenAI
:
return
self
.
_client
def
model_profile
(
self
,
model_name
:
str
)
->
ModelProfile
|
None
:
provider_to_profile
=
{
'xai'
:
grok_model_profile
,
'meta'
:
meta_model_profile
,
'microsoft'
:
openai_model_profile
,
'mistral-ai'
:
mistral_model_profile
,
'cohere'
:
cohere_model_profile
,
'deepseek'
:
deepseek_model_profile
,
}
profile
=
None
# If the model name does not contain a provider prefix, we assume it's an OpenAI model
if
'/'
not
in
model_name
:
return
openai_model_profile
(
model_name
)
provider
,
model_name
=
model_name
.
lower
()
.
split
(
'/'
,
1
)
if
provider
in
provider_to_profile
:
model_name
,
*
_
=
model_name
.
split
(
':'
,
1
)
# drop tags
profile
=
provider_to_profile
[
provider
](
model_name
)
# As GitHubProvider is always used with OpenAIModel, which used to unconditionally use OpenAIJsonSchemaTransformer,
# we need to maintain that behavior unless json_schema_transformer is set explicitly
return
OpenAIModelProfile
(
json_schema_transformer
=
OpenAIJsonSchemaTransformer
)
.
update
(
profile
)
@overload
def
__init__
(
self
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
api_key
:
str
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
api_key
:
str
,
http_client
:
AsyncHTTPClient
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
openai_client
:
AsyncOpenAI
|
None
=
None
)
->
None
:
...
def
__init__
(
self
,
*
,
api_key
:
str
|
None
=
None
,
openai_client
:
AsyncOpenAI
|
None
=
None
,
http_client
:
AsyncHTTPClient
|
None
=
None
,
)
->
None
:
"""Create a new GitHub Models provider.
Args:
api_key: The GitHub token to use for authentication. If not provided, the `GITHUB_API_KEY`
environment variable will be used if available.
openai_client: An existing `AsyncOpenAI` client to use. If provided, `api_key` and `http_client` must be `None`.
http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.
"""
api_key
=
api_key
or
os
.
getenv
(
'GITHUB_API_KEY'
)
if
not
api_key
and
openai_client
is
None
:
raise
UserError
(
'Set the `GITHUB_API_KEY` environment variable or pass it via `GitHubProvider(api_key=...)`'
' to use the GitHub Models provider.'
)
if
openai_client
is
not
None
:
self
.
_client
=
openai_client
elif
http_client
is
not
None
:
self
.
_client
=
AsyncOpenAI
(
base_url
=
self
.
base_url
,
api_key
=
api_key
,
http_client
=
http_client
)
else
:
http_client
=
cached_async_http_client
(
provider
=
'github'
)
self
.
_client
=
AsyncOpenAI
(
base_url
=
self
.
base_url
,
api_key
=
api_key
,
http_client
=
http_client
)
__init__
__init__
()
->
None
__init__
(
*
,
api_key
:
str
)
->
None
__init__
(
*
,
api_key
:
str
,
http_client
:
AsyncClient
)
->
None
__init__
(
*
,
openai_client
:
AsyncOpenAI
|
None
=
None
)
->
None
__init__
(
*
,
api_key
:
str
|
None
=
None
,
openai_client
:
AsyncOpenAI
|
None
=
None
,
http_client
:
AsyncClient
|
None
=
None
)
->
None
Create a new GitHub Models provider.
Parameters:
Name
Type
Description
Default
api_key
str
| None
The GitHub token to use for authentication. If not provided, the
GITHUB_API_KEY
environment variable will be used if available.
None
openai_client
AsyncOpenAI
| None
An existing
AsyncOpenAI
client to use. If provided,
api_key
and
http_client
must be
None
.
None
http_client
AsyncClient
| None
An existing
httpx.AsyncClient
to use for making HTTP requests.
None
Source code in
pydantic_ai_slim/pydantic_ai/providers/github.py
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
def
__init__
(
self
,
*
,
api_key
:
str
|
None
=
None
,
openai_client
:
AsyncOpenAI
|
None
=
None
,
http_client
:
AsyncHTTPClient
|
None
=
None
,
)
->
None
:
"""Create a new GitHub Models provider.
Args:
api_key: The GitHub token to use for authentication. If not provided, the `GITHUB_API_KEY`
environment variable will be used if available.
openai_client: An existing `AsyncOpenAI` client to use. If provided, `api_key` and `http_client` must be `None`.
http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.
"""
api_key
=
api_key
or
os
.
getenv
(
'GITHUB_API_KEY'
)
if
not
api_key
and
openai_client
is
None
:
raise
UserError
(
'Set the `GITHUB_API_KEY` environment variable or pass it via `GitHubProvider(api_key=...)`'
' to use the GitHub Models provider.'
)
if
openai_client
is
not
None
:
self
.
_client
=
openai_client
elif
http_client
is
not
None
:
self
.
_client
=
AsyncOpenAI
(
base_url
=
self
.
base_url
,
api_key
=
api_key
,
http_client
=
http_client
)
else
:
http_client
=
cached_async_http_client
(
provider
=
'github'
)
self
.
_client
=
AsyncOpenAI
(
base_url
=
self
.
base_url
,
api_key
=
api_key
,
http_client
=
http_client
)
Bases:
Provider
[
AsyncOpenAI
]
Provider for OpenRouter API.
Source code in
pydantic_ai_slim/pydantic_ai/providers/openrouter.py
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
class
OpenRouterProvider
(
Provider
[
AsyncOpenAI
]):
"""Provider for OpenRouter API."""
@property
def
name
(
self
)
->
str
:
return
'openrouter'
@property
def
base_url
(
self
)
->
str
:
return
'https://openrouter.ai/api/v1'
@property
def
client
(
self
)
->
AsyncOpenAI
:
return
self
.
_client
def
model_profile
(
self
,
model_name
:
str
)
->
ModelProfile
|
None
:
provider_to_profile
=
{
'google'
:
google_model_profile
,
'openai'
:
openai_model_profile
,
'anthropic'
:
anthropic_model_profile
,
'mistralai'
:
mistral_model_profile
,
'qwen'
:
qwen_model_profile
,
'x-ai'
:
grok_model_profile
,
'cohere'
:
cohere_model_profile
,
'amazon'
:
amazon_model_profile
,
'deepseek'
:
deepseek_model_profile
,
'meta-llama'
:
meta_model_profile
,
}
profile
=
None
provider
,
model_name
=
model_name
.
split
(
'/'
,
1
)
if
provider
in
provider_to_profile
:
model_name
,
*
_
=
model_name
.
split
(
':'
,
1
)
# drop tags
profile
=
provider_to_profile
[
provider
](
model_name
)
# As OpenRouterProvider is always used with OpenAIModel, which used to unconditionally use OpenAIJsonSchemaTransformer,
# we need to maintain that behavior unless json_schema_transformer is set explicitly
return
OpenAIModelProfile
(
json_schema_transformer
=
OpenAIJsonSchemaTransformer
)
.
update
(
profile
)
@overload
def
__init__
(
self
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
api_key
:
str
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
api_key
:
str
,
http_client
:
AsyncHTTPClient
)
->
None
:
...
@overload
def
__init__
(
self
,
*
,
openai_client
:
AsyncOpenAI
|
None
=
None
)
->
None
:
...
def
__init__
(
self
,
*
,
api_key
:
str
|
None
=
None
,
openai_client
:
AsyncOpenAI
|
None
=
None
,
http_client
:
AsyncHTTPClient
|
None
=
None
,
)
->
None
:
api_key
=
api_key
or
os
.
getenv
(
'OPENROUTER_API_KEY'
)
if
not
api_key
and
openai_client
is
None
:
raise
UserError
(
'Set the `OPENROUTER_API_KEY` environment variable or pass it via `OpenRouterProvider(api_key=...)`'
'to use the OpenRouter provider.'
)
if
openai_client
is
not
None
:
self
.
_client
=
openai_client
elif
http_client
is
not
None
:
self
.
_client
=
AsyncOpenAI
(
base_url
=
self
.
base_url
,
api_key
=
api_key
,
http_client
=
http_client
)
else
:
http_client
=
cached_async_http_client
(
provider
=
'openrouter'
)
self
.
_client
=
AsyncOpenAI
(
base_url
=
self
.
base_url
,
api_key
=
api_key
,
http_client
=
http_client
)